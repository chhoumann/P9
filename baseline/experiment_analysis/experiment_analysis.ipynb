{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from lib.config import AppConfig\n",
    "from experiment_analysis.experiment_data_utils import get_full_runs_df\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "config = AppConfig()\n",
    "mlflow.set_tracking_uri(config.mlflow_tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "runs = get_full_runs_df(config.optimization_experiment_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "len(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from lib.reproduction import major_oxides\n",
    "\n",
    "analysis_target = \"SiO2\"\n",
    "n_splits=4\n",
    "assert analysis_target in major_oxides, f\"{analysis_target} is not a valid oxide. Please choose from {major_oxides}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from experiment_analysis.experiment_data_utils import clean_experiment_data\n",
    "\n",
    "filtered_runs = clean_experiment_data(runs)\n",
    "\n",
    "filtered_runs = filtered_runs[filtered_runs['metrics.rmse_cv'] <= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "filtered_runs[\"params.oxide\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def display_table_with_options(df, max_columns=10, max_rows=100, display_func=lambda x: display(x)):\n",
    "    original_max_columns = pd.get_option('display.max_columns')\n",
    "    original_max_rows = pd.get_option('display.max_rows')\n",
    "\n",
    "    pd.set_option('display.max_columns', max_columns)\n",
    "    pd.set_option('display.max_rows', max_rows)\n",
    "\n",
    "    display_func(df)\n",
    "\n",
    "    pd.set_option('display.max_columns', original_max_columns)\n",
    "    pd.set_option('display.max_rows', original_max_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "overview_list = []\n",
    "for oxide in major_oxides:\n",
    "    overview_df = filtered_runs[[\"params.oxide\", \"params.model_type\", \"params.transformer_type\", \"params.pca_type\", \"params.scaler_type\", \"metrics.rmse_cv\", \"metrics.std_dev_cv\", \"metrics.rmse\"]]\n",
    "\n",
    "    overview_df = overview_df[overview_df['params.oxide'] == oxide].sort_values(by='metrics.rmse_cv')\n",
    "    unique_model_types_df = overview_df.drop_duplicates(subset=['params.model_type'])\n",
    "    overview_list.append(unique_model_types_df)\n",
    "\n",
    "for oxide, df in zip(major_oxides, overview_list):\n",
    "    display(HTML(f\"<h2>{oxide}</h2>\"))\n",
    "    display_table_with_options(df, max_columns=10, max_rows=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "cols = \"\"\n",
    "for col in filtered_runs.columns:\n",
    "    cols += f\"{col}, \"\n",
    "\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for oxide in  major_oxides:\n",
    "    oxide_name = \"FeO_T\" if oxide == \"FeOT\" else oxide\n",
    "\n",
    "    overview_df = filtered_runs[[\"params.oxide\", \"params.model_type\", \"params.transformer_type\", \"params.pca_type\", \"params.scaler_type\", \"metrics.rmse_cv\", \"metrics.std_dev_cv\", \"metrics.rmse\"]]\n",
    "    overview_df = overview_df[overview_df['params.oxide'] == oxide].sort_values(by='metrics.rmse_cv')\n",
    "\n",
    "    # Prepare the DataFrame for LaTeX conversion\n",
    "    overview_df['params.oxide'] = overview_df['params.oxide'].apply(lambda x: f\"\")\n",
    "    overview_df['params.model_type'] = overview_df['params.model_type'].apply(lambda x: f\"\\\\texttt{{{x.replace('_', '\\\\_')}}}\")\n",
    "    overview_df['params.transformer_type'] = overview_df['params.transformer_type'].apply(lambda x: f\"\\\\texttt{{{x.replace('_', '\\\\_')}}}\")\n",
    "    overview_df['params.pca_type'] = overview_df['params.pca_type'].apply(lambda x: f\"\\\\texttt{{{x.replace('_', '\\\\_')}}}\")\n",
    "    overview_df['params.scaler_type'] = overview_df['params.scaler_type'].apply(lambda x: f\"\\\\texttt{{{x.replace('_', '\\\\_')}}}\")\n",
    "\n",
    "    # Format numerical columns to show only 2 decimals\n",
    "    overview_df['metrics.rmse_cv'] = overview_df['metrics.rmse_cv'].apply(lambda x: f\"{x:.3f}\")\n",
    "    overview_df['metrics.std_dev_cv'] = overview_df['metrics.std_dev_cv'].apply(lambda x: f\"{x:.3f}\")\n",
    "    overview_df['metrics.rmse'] = overview_df['metrics.rmse'].apply(lambda x: f\"{x:.3f}\")\n",
    "\n",
    "    # Rename columns to match the required headers\n",
    "    overview_df = overview_df.rename(columns={\n",
    "        'params.oxide': \"\\\\ce{\" + oxide_name + \"}\",\n",
    "        'params.model_type': 'Model Type',\n",
    "        'params.transformer_type': 'Transformer Type',\n",
    "        'params.pca_type': 'PCA Type',\n",
    "        'params.scaler_type': 'Scaler Type',\n",
    "        'metrics.rmse_cv': '\\\\gls{rmsecv}',\n",
    "        'metrics.std_dev_cv': 'Std. dev. CV',\n",
    "        'metrics.rmse': '\\\\gls{rmsep}'\n",
    "    })\n",
    "\n",
    "    path = Path(f\"./../../report_thesis/src/sections/appendix/tables/{oxide}_overview.tex\")\n",
    "\n",
    "    unique_model_types_df = overview_df.drop_duplicates(subset=['Model Type'])\n",
    "\n",
    "    # Generate the LaTeX table with table* environment\n",
    "    latex_table = unique_model_types_df.to_latex(index=False, escape=False)\n",
    "\n",
    "    with open(path, \"w\") as file:\n",
    "        file.write(\"\\\\begin{table*}[htbp]\\n\")\n",
    "        file.write(\"\\\\centering\\n\")\n",
    "        file.write(latex_table)\n",
    "        file.write(\"\\\\caption{Overview of model types for \\\\ce{\" + oxide_name + \"} oxide}\\n\")\n",
    "        file.write(\"\\\\label{tab:\" + oxide + \"_overview}\\n\")\n",
    "        file.write(\"\\\\end{table*}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from experiment_analysis.experiment_data_utils import pretty_format_params\n",
    "\n",
    "model_categories = {\n",
    "    \"gradient_boosting\": [\"gbr\", \"xgboost\", \"ngboost\"],\n",
    "    \"tree_based\": [\"extra_trees\", \"random_forest\"],\n",
    "    \"linear_models\": [\"lasso\", \"ridge\", \"elasticnet\"],\n",
    "    \"svm\": [\"svr\"],\n",
    "    \"pls\": [\"pls\"]\n",
    "}\n",
    "\n",
    "overview_list = []\n",
    "for oxide in major_oxides:\n",
    "    overview_df = filtered_runs[[\"params.oxide\", \"params.model_type\", \"params.transformer_type\", \"params.pca_type\", \"params.scaler_type\", \"metrics.rmse_cv\", \"metrics.std_dev_cv\"]]\n",
    "\n",
    "    overview_df = overview_df[overview_df['params.oxide'] == oxide].sort_values(by='metrics.rmse_cv')\n",
    "    unique_model_types_df = overview_df.drop_duplicates(subset=['params.model_type'])\n",
    "    overview_list.append(unique_model_types_df)\n",
    "\n",
    "max_models_per_category = 10\n",
    "max_models_per_oxide = 10\n",
    "for oxide, df in zip(major_oxides, overview_list):\n",
    "    display(HTML(f\"<h2>{oxide}</h2>\"))\n",
    "    display(HTML(\"<h3>Top 3 Configurations</h3>\"))\n",
    "    category_counter = {category: 0 for category in model_categories.keys()}\n",
    "\n",
    "    model_counter = 0\n",
    "    for i, row in df.iterrows():\n",
    "        if model_counter >= max_models_per_oxide:\n",
    "            break\n",
    "        model_type = row['params.model_type']\n",
    "        for category, models in model_categories.items():\n",
    "            if model_type in models:\n",
    "                if category_counter[category] < max_models_per_category:\n",
    "                    category_counter[category] += 1\n",
    "                    model_counter += 1\n",
    "                    data_row = filtered_runs.loc[row.name]\n",
    "                    print(pretty_format_params(data_row))\n",
    "                    print(f\"RMSEP: {data_row['metrics.rmse']}\")\n",
    "                    print(f\"Std.Dev: {data_row['metrics.std_dev']}\")\n",
    "                    print(f\"RMSE CV: {data_row['metrics.rmse_cv']}\")\n",
    "                    print(f\"STD Dev CV: {data_row['metrics.std_dev_cv']}\")\n",
    "                    print(\"\\n\")\n",
    "                break\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_runs[filtered_runs['params.oxide'] == analysis_target][\"metrics.rmse_cv\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group filtered_runs by the specified parameters and sort by metrics.rmsecv\n",
    "grouped_runs = filtered_runs.groupby(\n",
    "    ['params.model_type', 'params.transformer_type', 'params.pca_type', 'params.scaler_type', 'params.oxide']\n",
    ").apply(lambda x: x.sort_values(by='metrics.rmse_cv').head(1)).reset_index(drop=True)\n",
    "\n",
    "# Create a pivot table to show the best configurations for each oxide\n",
    "pivot_table = grouped_runs.pivot_table(\n",
    "    index=['params.model_type', 'params.transformer_type', 'params.scaler_type', 'params.pca_type'],\n",
    "    columns='params.oxide',\n",
    "    values='metrics.rmse_cv',\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display the pivot table\n",
    "display(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_runs = filtered_runs[filtered_runs['params.oxide'] == analysis_target]\n",
    "len(filtered_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "total_runs = len(runs)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='params.model_type', y='metrics.rmse', data=filtered_runs)\n",
    "plt.title(f\"{analysis_target}: RMSE for each model type - {len(filtered_runs)} runs out of {total_runs} total runs\")\n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.ylabel(\"RMSEP\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the runs that minimize rmse, rmse_cv, std_dev, and std_dev_cv\n",
    "optimal_runs = filtered_runs.loc[filtered_runs[['metrics.rmse', 'metrics.rmse_cv', 'metrics.std_dev', 'metrics.std_dev_cv']].idxmin()]\n",
    "\n",
    "# Display the optimal runs\n",
    "optimal_runs[['metrics.rmse', 'metrics.rmse_cv', 'metrics.std_dev', 'metrics.std_dev_cv', 'params.model_type']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting RMSE CV\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.boxplot(x='params.model_type', y='metrics.rmse_cv', data=filtered_runs)\n",
    "plt.title(f'{analysis_target}: Average Cross-Validation RMSE by Model Type')\n",
    "plt.ylabel('Average RMSE (Cross-Validation)')\n",
    "plt.show()\n",
    "\n",
    "# Plotting Standard Deviation of RMSE CV\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.boxplot(x='params.model_type', y='metrics.std_dev_cv', data=filtered_runs)\n",
    "plt.title(f'{analysis_target}: Standard Deviation of Errors (Cross-Validation) by Model Type')\n",
    "plt.ylabel('Standard Deviation of Errors (CV)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a melted DataFrame for seaborn plotting\n",
    "melted_df = filtered_runs.melt(id_vars=['params.model_type'], value_vars=[f'metrics.rmse_cv_{i+1}' for i in range(n_splits)],\n",
    "                               var_name='CV Fold', value_name='Fold RMSE')\n",
    "\n",
    "# Plotting without outliers\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='params.model_type', y='Fold RMSE', hue='CV Fold', data=melted_df, showfliers=False)\n",
    "plt.title(f'{analysis_target}: Distribution of RMSE Across CV Folds by Model Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_columns = [\n",
    "    'metrics.rmse_cv', 'params.model_type', 'params.scaler_type',\n",
    "    'params.transformer_type', 'params.pca_type'\n",
    "]\n",
    "filtered_runs_new = runs[cv_columns]\n",
    "filtered_runs_new = filtered_runs_new[filtered_runs_new['metrics.rmse_cv'] <= 50]\n",
    "\n",
    "\n",
    "# Rename columns for clarity\n",
    "rename_dict = {col: col.split('.')[-1] for col in cv_columns}\n",
    "filtered_runs_new = filtered_runs_new.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Individual Parameters\n",
    "for parameter in ['model_type', 'scaler_type', 'transformer_type', 'pca_type']:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    chart = sns.barplot(x=parameter, y='rmse_cv', data=filtered_runs_new)\n",
    "    chart.set_xticks(range(len(filtered_runs_new[parameter].unique())))\n",
    "    chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    plt.title(f'{analysis_target}: Average RMSE (CV) by {parameter.capitalize()}')\n",
    "    plt.ylabel('Average RMSE (CV)')\n",
    "    plt.show()\n",
    "\n",
    "# Combinations of Parameters\n",
    "# Considering combinations might result in a lot of categories, focus on the top few based on average RMSE\n",
    "combination_data = filtered_runs_new.groupby(['model_type', 'scaler_type', 'transformer_type', 'pca_type']).mean()['rmse_cv']\n",
    "combination_data = combination_data.reset_index().sort_values(by='rmse_cv', ascending=True)\n",
    "\n",
    "# Display top 10 combinations\n",
    "print(combination_data.head(10))\n",
    "\n",
    "# Optionally, visualize these top combinations\n",
    "plt.figure(figsize=(14, 8))\n",
    "combination_data_top10 = combination_data[:10]\n",
    "combination_labels = combination_data_top10.apply(lambda row: ', '.join([str(row[param]) for param in ['model_type', 'scaler_type', 'transformer_type', 'pca_type'] if row[param] != 'none']), axis=1)\n",
    "sns.barplot(x='rmse_cv', y=combination_labels, data=combination_data_top10, orient='h')\n",
    "plt.title(f'{analysis_target}: Top 10 Combinations for RMSE Performance')\n",
    "plt.xlabel('Average RMSE (Cross-Validation)')\n",
    "plt.ylabel('Combinations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data to compute mean and standard deviation of RMSE for each configuration\n",
    "# Lower RMSE (lower is better) and lower STD RMSE (lower is better for consistency)\n",
    "aggregated_data = filtered_runs_new.groupby(['model_type', 'scaler_type', 'transformer_type', 'pca_type']).agg({\n",
    "    'rmse_cv': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the columns (multi-level index after aggregation)\n",
    "aggregated_data.columns = ['Model Type', 'Scaler Type', 'Transformer Type', 'PCA Type', 'Mean RMSECV', 'STD RMSECV']\n",
    "\n",
    "# Sort configurations first by mean RMSE (ascending, lower is better) and then by STD RMSE (ascending, lower is better for consistency)\n",
    "sorted_data = aggregated_data.sort_values(by=['Mean RMSECV', 'STD RMSECV'], ascending=[True, True])\n",
    "\n",
    "# Display the top 10 consistently good configurations\n",
    "print(sorted_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting the top configurations based on Mean RMSE\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = 50\n",
    "for parameter in ['Model Type', 'Scaler Type', 'Transformer Type', 'PCA Type']:\n",
    "    top_configurations = sns.barplot(x='Mean RMSECV', y=parameter, hue=parameter, data=sorted_data.head(top_n), dodge=False)\n",
    "    plt.title(f'{analysis_target}: Top {top_n} Configurations by Mean RMSECV and Their Consistency')\n",
    "    plt.xlabel('Mean RMSECV')\n",
    "    plt.ylabel(parameter)\n",
    "    # Annotate each bar with the value of Mean RMSE\n",
    "    for p in top_configurations.patches:\n",
    "        width = p.get_width()\n",
    "        plt.text(width + 0.01, p.get_y()+0.2 + p.get_height() / 2, f'{width:.2f}', ha='left', va='center')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = filtered_runs.sort_values(by=\"metrics.rmse_cv\").iloc[0]\n",
    "non_none_columns = first_row[first_row.notna()].index.tolist()\n",
    "first_row[non_none_columns]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

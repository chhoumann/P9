{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.reproduction import major_oxides\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import torch\n",
    "import keras\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_regression_optimized.py\n",
    "from keras import layers, optimizers, regularizers\n",
    "\n",
    "def build_model(input_dim, output_dim):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    model.add(layers.Reshape((48, 128, 1)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Additional convolutional block for better feature extraction\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(output_dim))\n",
    "\n",
    "    # Using L2 regularization\n",
    "    model.add(layers.Dense(output_dim, kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "    # Optimizer with a custom learning rate\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['root_mean_squared_error', 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 6144  # Number of features per sample\n",
    "OUTPUT_DIM = 1    # Number of continuous values as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(INPUT_DIM, OUTPUT_DIM):\n",
    "    # def transformer_encoder(inputs, embed_dim, num_heads):\n",
    "    #     # Transformer encoder layer\n",
    "    #     attention_output = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
    "    #     attention_output = keras.layers.Dropout(0.1)(attention_output)\n",
    "    #     attention_output = keras.layers.Add()([attention_output, inputs])\n",
    "    #     return attention_output\n",
    "\n",
    "    inputs = keras.Input(shape=(INPUT_DIM, 1))\n",
    "    x = keras.layers.BatchNormalization()(inputs)\n",
    "\n",
    "    # # Inception module\n",
    "    # tower_1 = keras.layers.Conv1D(filters=32, kernel_size=1, padding='same', activation='relu')(x)\n",
    "    # tower_2 = keras.layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    # tower_3 = keras.layers.Conv1D(filters=32, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    # x = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "\n",
    "\n",
    "    x = keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding='same', activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "\n",
    "    residual1 = keras.layers.Conv1D(filters=64, kernel_size=1, strides=2, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Incorporate the first residual connection\n",
    "    x = keras.layers.Add()([x, residual1])\n",
    "\n",
    "    x = keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    residual2 = keras.layers.Conv1D(filters=128, kernel_size=1, strides=2, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "\n",
    "    x = keras.layers.Add()([x, residual2])\n",
    "\n",
    "    # embed_dim = 64  # Set this based on your model's architecture\n",
    "    # num_heads = 2   # Number of attention heads in the MultiHeadAttention layer\n",
    "    # x = transformer_encoder(x, embed_dim, num_heads)\n",
    "\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.Dense(512, activation='relu')(x)\n",
    "    output = keras.layers.Dense(OUTPUT_DIM, activation='linear')(x)  # Assuming prediction of 8 continuous target variables\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['root_mean_squared_error', 'mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = major_oxides + [\"ID\", \"Sample Name\"]\n",
    "target_cols = major_oxides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.cross_validation import (\n",
    "    get_cross_validation_metrics,\n",
    ")\n",
    "from lib.metrics import rmse_metric, std_dev_metric\n",
    "from functools import partial\n",
    "from lib.deep_learning_utils import get_preprocess_fn, MLFlowCallback\n",
    "from experiments.optuna_run import get_data\n",
    "\n",
    "\n",
    "early_stopping_callback = partial(\n",
    "    keras.callbacks.EarlyStopping, monitor=\"val_loss\", patience=25, restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "mlflow.set_experiment(f'CNN_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "\n",
    "args = {\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "def check_group_overlap(train_set, validation_set, group_column=\"Sample Name\"):\n",
    "    train_groups = set(train_set[group_column].unique())\n",
    "    validation_groups = set(validation_set[group_column].unique())\n",
    "    overlap = train_groups.intersection(validation_groups)\n",
    "    assert len(overlap) == 0, f\"Data leakage detected: {overlap}\"\n",
    "\n",
    "def split_dataset_by_group(dataset, split_ratio: float, group_column=\"Sample Name\"):\n",
    "    unique_groups = dataset[group_column].unique()\n",
    "    selected_groups = np.random.choice(unique_groups, size=int(split_ratio * len(unique_groups)), replace=False)\n",
    "    training_set = dataset[dataset[group_column].isin(selected_groups)]\n",
    "    remaining_set = dataset[~dataset[group_column].isin(selected_groups)]\n",
    "\n",
    "    # Check for group overlap\n",
    "    check_group_overlap(training_set, remaining_set, group_column)\n",
    "\n",
    "    return training_set, remaining_set\n",
    "\n",
    "SPLIT_RATIO = 0.2\n",
    "for target in major_oxides:\n",
    "    folds, train, test = get_data(target)\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"CNN_{target}\"):\n",
    "        # == CROSS VALIDATION ==\n",
    "        cv_metrics = []\n",
    "        for cv_train_data, cv_test_data in folds:\n",
    "            train_cv, val_cv = split_dataset_by_group(cv_train_data, SPLIT_RATIO)\n",
    "            check_group_overlap(train_cv, val_cv, \"Sample Name\")\n",
    "\n",
    "            model = build_model_2(INPUT_DIM, OUTPUT_DIM)\n",
    "\n",
    "            preprocess_fn = get_preprocess_fn([target], drop_cols)\n",
    "            X_train, y_train = preprocess_fn(train_cv)\n",
    "            X_val, y_val = preprocess_fn(val_cv)\n",
    "            X_test, y_test = preprocess_fn(cv_test_data)\n",
    "\n",
    "            model.fit(\n",
    "                X_train, y_train, **args, callbacks=[early_stopping_callback()], validation_data=(X_val, y_val)\n",
    "            )  # don't want to use mlflow callback here\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            rmse = rmse_metric(y_test, y_pred)\n",
    "            std_dev = std_dev_metric(y_test, y_pred)\n",
    "            cv_metrics.append([rmse, std_dev])\n",
    "\n",
    "        mlflow.log_metrics(get_cross_validation_metrics(cv_metrics).as_dict())\n",
    "\n",
    "        # == TRAIN ON ALL DATA ==\n",
    "        model = build_model_2(INPUT_DIM, OUTPUT_DIM)\n",
    "        preprocess_fn = get_preprocess_fn([target], drop_cols)\n",
    "        train, validation = split_dataset_by_group(train, SPLIT_RATIO)\n",
    "\n",
    "        check_group_overlap(train, validation, \"Sample Name\")\n",
    "\n",
    "        X_train, y_train = preprocess_fn(train)\n",
    "        X_val, y_val = preprocess_fn(validation)\n",
    "        X_test, y_test = preprocess_fn(test)\n",
    "\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            **args,\n",
    "            callbacks=[MLFlowCallback(), early_stopping_callback()],\n",
    "            validation_data=(X_val, y_val),\n",
    "        )\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        std_dev = std_dev_metric(y_test, y_pred)\n",
    "        rmse = rmse_metric(y_test, y_pred)\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"std_dev\": std_dev})\n",
    "\n",
    "        mlflow.log_params({**args, \"target\": target})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

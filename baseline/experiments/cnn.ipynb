{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.reproduction import major_oxides\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lib import full_flow_dataloader\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import torch\n",
    "import keras\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed, test_processed = full_flow_dataloader.load_full_flow_data(load_cache_if_exits=True, average_shots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (6, 16, 128) and (12, 32, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m OUTPUT_DIM \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m    \u001b[38;5;66;03m# Number of continuous values as output\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Model Creation\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[78], line 28\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(input_dim, output_dim)\u001b[0m\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBatchNormalization()(x)\n\u001b[0;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortcut2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mActivation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling2D()(x)\n",
      "File \u001b[0;32m~/projects/p9/baseline/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/projects/p9/baseline/venv/lib/python3.12/site-packages/keras/src/layers/merging/base_merge.py:56\u001b[0m, in \u001b[0;36mMerge._compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m---> 56\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     57\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs have incompatible shapes. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m             )\n\u001b[1;32m     60\u001b[0m         output_shape\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (6, 16, 128) and (12, 32, 64)"
     ]
    }
   ],
   "source": [
    "# cnn_regression_optimized.py\n",
    "from keras import layers, optimizers, regularizers, Model\n",
    "\n",
    "def build_model(input_dim, output_dim):\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Reshape((48, 128, 1))(inputs)\n",
    "\n",
    "    # Initial convolutional layer\n",
    "    x = layers.Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Residual block 1\n",
    "    shortcut1 = x\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, shortcut1])\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    # Residual block 2\n",
    "    shortcut2 = x\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, shortcut2])\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Using OUTPUT_DIM parallel layers to output the target value, then concatenate\n",
    "    outputs = [layers.Dense(1, kernel_regularizer=regularizers.l2(0.01))(x) for i in range(output_dim)]\n",
    "    if len(outputs) > 1:\n",
    "        outputs = layers.Concatenate()(outputs)\n",
    "    else:\n",
    "        outputs = outputs[0]  # If only one output, no need to concatenate\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Optimizer with a custom learning rate\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['root_mean_squared_error', 'mae'])\n",
    "    return model\n",
    "\n",
    "# Constants\n",
    "INPUT_DIM = 6144  # Number of features per sample\n",
    "OUTPUT_DIM = 8    # Number of continuous values as output\n",
    "\n",
    "# Model Creation\n",
    "model = build_model(INPUT_DIM, OUTPUT_DIM)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = major_oxides + [\"ID\", \"Sample Name\"]\n",
    "\n",
    "X_train = train_processed.drop(columns=drop_cols)\n",
    "y_train = train_processed[major_oxides]\n",
    "\n",
    "X_test = test_processed.drop(columns=drop_cols)\n",
    "y_test = test_processed[major_oxides]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.to_numpy().reshape(-1, 6144, 1)\n",
    "X_test_reshaped = X_test.to_numpy().reshape(-1, 6144, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn_experiment(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: keras.Model,\n",
    "    epochs: int,\n",
    "    batch_size: int,\n",
    "    callbacks: list = [],\n",
    "    major_oxides: list = [],\n",
    "):\n",
    "    with mlflow.start_run(run_name=\"CNN\"):\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=callbacks)\n",
    "        y_pred = model.predict(X_test)\n",
    "        for i, oxide in enumerate(major_oxides):\n",
    "            y_test_oxide = y_test[:, i]\n",
    "            y_pred_oxide = y_pred[:, i]\n",
    "            rmse = mean_squared_error(y_test_oxide, y_pred_oxide, squared=False)\n",
    "            mlflow.log_metric(f\"rmse_{oxide}\", float(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/19 11:12:49 INFO mlflow.tracking.fluent: Experiment with name 'CNN_Res_20240419-111245' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 335.4956 - mean_absolute_error: 9.7895 - val_loss: 280.2798 - val_mean_absolute_error: 10.1345\n",
      "Epoch 2/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 35.9537 - mean_absolute_error: 4.3526 - val_loss: 238.6214 - val_mean_absolute_error: 9.8099\n",
      "Epoch 3/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 29.2822 - mean_absolute_error: 3.7743 - val_loss: 88.1235 - val_mean_absolute_error: 4.9903\n",
      "Epoch 4/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 24.0560 - mean_absolute_error: 3.3637 - val_loss: 90.7203 - val_mean_absolute_error: 5.0241\n",
      "Epoch 5/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 22.1862 - mean_absolute_error: 3.1414 - val_loss: 84.3762 - val_mean_absolute_error: 4.7604\n",
      "Epoch 6/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 19.6694 - mean_absolute_error: 2.9276 - val_loss: 69.7693 - val_mean_absolute_error: 4.1859\n",
      "Epoch 7/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 17.8358 - mean_absolute_error: 2.7233 - val_loss: 90.0686 - val_mean_absolute_error: 5.2193\n",
      "Epoch 8/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 18.5060 - mean_absolute_error: 2.7203 - val_loss: 75.3878 - val_mean_absolute_error: 4.8324\n",
      "Epoch 9/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 17.7479 - mean_absolute_error: 2.6447 - val_loss: 69.8928 - val_mean_absolute_error: 4.2805\n",
      "Epoch 10/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 16.0955 - mean_absolute_error: 2.5030 - val_loss: 58.9640 - val_mean_absolute_error: 4.3307\n",
      "Epoch 11/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 13.9227 - mean_absolute_error: 2.3254 - val_loss: 60.7062 - val_mean_absolute_error: 4.3072\n",
      "Epoch 12/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 14.4100 - mean_absolute_error: 2.3435 - val_loss: 46.2781 - val_mean_absolute_error: 3.7395\n",
      "Epoch 13/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 13.5942 - mean_absolute_error: 2.2681 - val_loss: 49.6419 - val_mean_absolute_error: 3.9707\n",
      "Epoch 14/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 12.5402 - mean_absolute_error: 2.1725 - val_loss: 52.9678 - val_mean_absolute_error: 3.7831\n",
      "Epoch 15/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 12.3551 - mean_absolute_error: 2.1508 - val_loss: 43.8246 - val_mean_absolute_error: 3.4335\n",
      "Epoch 16/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 11.9401 - mean_absolute_error: 2.0941 - val_loss: 63.6056 - val_mean_absolute_error: 4.3360\n",
      "Epoch 17/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 11.5821 - mean_absolute_error: 2.0801 - val_loss: 39.1163 - val_mean_absolute_error: 3.4817\n",
      "Epoch 18/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 11.8863 - mean_absolute_error: 2.1232 - val_loss: 44.9500 - val_mean_absolute_error: 3.7305\n",
      "Epoch 19/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 12.6867 - mean_absolute_error: 2.1157 - val_loss: 49.6701 - val_mean_absolute_error: 3.8754\n",
      "Epoch 20/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 11.6787 - mean_absolute_error: 2.0836 - val_loss: 68.5455 - val_mean_absolute_error: 4.3337\n",
      "Epoch 21/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 11.8698 - mean_absolute_error: 2.0742 - val_loss: 41.7847 - val_mean_absolute_error: 3.7976\n",
      "Epoch 22/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 11.5991 - mean_absolute_error: 2.0287 - val_loss: 38.6410 - val_mean_absolute_error: 3.5519\n",
      "Epoch 23/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 10.6703 - mean_absolute_error: 1.9729 - val_loss: 40.4143 - val_mean_absolute_error: 3.5845\n",
      "Epoch 24/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 10.9208 - mean_absolute_error: 1.9833 - val_loss: 50.7446 - val_mean_absolute_error: 3.5783\n",
      "Epoch 25/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 10.1498 - mean_absolute_error: 1.9188 - val_loss: 41.8079 - val_mean_absolute_error: 3.3313\n",
      "Epoch 26/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 10.2480 - mean_absolute_error: 1.9332 - val_loss: 33.5403 - val_mean_absolute_error: 3.1719\n",
      "Epoch 27/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 9.7860 - mean_absolute_error: 1.8764 - val_loss: 32.1603 - val_mean_absolute_error: 3.0151\n",
      "Epoch 28/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 10.0024 - mean_absolute_error: 1.8754 - val_loss: 46.4054 - val_mean_absolute_error: 3.5860\n",
      "Epoch 29/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 10.6025 - mean_absolute_error: 1.9559 - val_loss: 32.2707 - val_mean_absolute_error: 3.2037\n",
      "Epoch 30/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 10.7294 - mean_absolute_error: 1.9564 - val_loss: 36.4807 - val_mean_absolute_error: 3.2616\n",
      "Epoch 31/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 9.0232 - mean_absolute_error: 1.8302 - val_loss: 40.9658 - val_mean_absolute_error: 3.3292\n",
      "Epoch 32/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 9.1715 - mean_absolute_error: 1.8283 - val_loss: 32.8198 - val_mean_absolute_error: 3.0279\n",
      "Epoch 33/1000\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 9.0375 - mean_absolute_error: 1.8450 - val_loss: 40.0674 - val_mean_absolute_error: 3.3082\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/projects/p9/baseline/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/christian/projects/p9/baseline/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/christian/projects/p9/baseline/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/christian/projects/p9/baseline/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/christian/projects/p9/baseline/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/christian/projects/p9/baseline/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/christian/projects/p9/baseline/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/christian/projects/p9/baseline/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)\n",
    "\n",
    "class MLFlowCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None:\n",
    "            for key, value in logs.items():\n",
    "                mlflow.log_metric(f\"{key}\", value, step=epoch)\n",
    "\n",
    "\n",
    "mlflow.set_experiment(f'CNN_Res_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "run_cnn_experiment(\n",
    "    X_train_reshaped,\n",
    "    y_train.to_numpy(),\n",
    "    X_test_reshaped,\n",
    "    y_test.to_numpy(),\n",
    "    model,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=[MLFlowCallback(), callback],\n",
    "    major_oxides=major_oxides,\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

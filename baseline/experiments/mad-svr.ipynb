{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data_handling import *\n",
    "from lib.reproduction import major_oxides, masks\n",
    "from lib.config import AppConfig\n",
    "from lib.norms import Norm1Scaler, Norm3Scaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import datetime\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemoverWithMAD(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=3.0, max_iterations=10):\n",
    "        self.k = k\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer does not need to learn anything from the data,\n",
    "        # so the fit method doesn't do anything besides returning self.\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Ensure X is a DataFrame (if it's not already)\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        # Apply the outlier removal logic\n",
    "        non_outlier_indices, _ = self.identify_outliers_with_mad_iterative_multidim(\n",
    "            X, self.k, self.max_iterations\n",
    "        )\n",
    "\n",
    "        # Initialize a boolean array for all indices, marking True for non-outliers\n",
    "        outlier_mask = np.zeros(len(X), dtype=bool)\n",
    "        outlier_mask[non_outlier_indices] = True   # True for non-outliers\n",
    "        outlier_mask = ~outlier_mask              # Invert to mark outliers\n",
    "\n",
    "        # Exclude wavelength column from being zeroed out\n",
    "        columns_to_zero = X.columns[X.columns != \"wave\"]\n",
    "        X.loc[outlier_mask, columns_to_zero] = 0\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    def identify_outliers_with_mad_iterative_multidim(self, X, k=3.0, max_iterations=10):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"X must be a pandas DataFrame.\")\n",
    "\n",
    "        # print larget x value\n",
    "        n_samples, n_features = X.shape\n",
    "        keep_mask = np.ones(n_samples, dtype=bool)\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            data = X.iloc[:, feature].to_numpy()\n",
    "            for iteration in range(max_iterations):\n",
    "                if not np.any(keep_mask):\n",
    "                    break\n",
    "\n",
    "                median = np.median(data[keep_mask])\n",
    "                absolute_deviation = np.abs(data[keep_mask] - median)\n",
    "                mad = np.median(absolute_deviation)\n",
    "                if mad == 0:\n",
    "                    break\n",
    "\n",
    "                modified_z_scores = 0.6745 * absolute_deviation / mad\n",
    "                outliers = modified_z_scores > k\n",
    "\n",
    "                keep_mask[keep_mask] = ~outliers\n",
    "\n",
    "                if not np.any(outliers):\n",
    "                    break\n",
    "\n",
    "        return np.where(keep_mask)[0], iteration + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SVRCustomSpectralPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        masks,\n",
    "        composition_data_loc,\n",
    "        major_oxides,\n",
    "    ):\n",
    "        self.pipeline = Pipeline(\n",
    "            [\n",
    "                (\"mask_transformer\", WavelengthMaskTransformer(masks)),\n",
    "                (\"non_negative_transformer\", NonNegativeTransformer()),\n",
    "                (\"outlier_remover\", OutlierRemoverWithMAD(k=3.0, max_iterations=10)),\n",
    "                (\"data_reshaper\", SpectralDataReshaper(wavelength_feature_name=\"wave\")),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.composition_data = CompositionData(composition_data_loc)\n",
    "        self.major_oxides = major_oxides\n",
    "\n",
    "    def _attach_major_oxides(\n",
    "        self,\n",
    "        transformed_df: pd.DataFrame,\n",
    "        sample_name: str,\n",
    "        location_name: str,\n",
    "    ):\n",
    "        sample_composition = self.composition_data.get_composition_for_sample(sample_name)\n",
    "\n",
    "        if sample_composition.empty:\n",
    "            raise ValueError(\"sample_composition is empty, cannot attach major oxides\")\n",
    "\n",
    "        oxides = sample_composition[self.major_oxides].iloc[0]\n",
    "        transformed_df = transformed_df.assign(**oxides)\n",
    "\n",
    "        transformed_df[\"Sample Name\"] = sample_name\n",
    "        transformed_df[\"ID\"] = f\"{sample_name}_{location_name}\"\n",
    "\n",
    "        return transformed_df\n",
    "\n",
    "    def fit_transform(self, sample_data: dict[str, Dict[str, pd.DataFrame]]):\n",
    "        transformed_samples = []\n",
    "\n",
    "        for sample_name, sample_location_dfs in tqdm(sample_data.items(), desc=\"Transforming samples\"):\n",
    "            for _, (location_name, sample_df) in enumerate(sample_location_dfs.items()):\n",
    "                if self.composition_data.get_composition_for_sample(sample_name=sample_name).empty:\n",
    "                    continue\n",
    "\n",
    "                transformed_df = self.pipeline.fit_transform(sample_df)\n",
    "\n",
    "                transformed_df = self._attach_major_oxides(pd.DataFrame(transformed_df), sample_name, location_name)\n",
    "                transformed_samples.append(transformed_df)\n",
    "\n",
    "        df_out = pd.concat(transformed_samples, ignore_index=True).rename(columns=str)\n",
    "\n",
    "        return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(load_cache_if_exits: bool = True, average_shots: bool = True):\n",
    "    \"\"\"\n",
    "    Loads the data for the full flow.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"train\")\n",
    "\n",
    "    config = AppConfig()\n",
    "    composition_data_loc = config.composition_data_path\n",
    "    dataset_loc = config.data_path\n",
    "\n",
    "    preformatted_data_path = Path(f\"{config.data_cache_dir}/_preformatted_mad/\")\n",
    "\n",
    "    data_hash = config.data_hash\n",
    "    train_path = preformatted_data_path / f\"train_{data_hash}.csv\"\n",
    "    test_path = preformatted_data_path / f\"test_{data_hash}.csv\"\n",
    "\n",
    "    if (\n",
    "        load_cache_if_exits\n",
    "        and preformatted_data_path.exists()\n",
    "        and train_path.exists()\n",
    "        and test_path.exists()\n",
    "    ):\n",
    "        logger.info(\n",
    "            \"Loading preformatted data from location: %s\", preformatted_data_path\n",
    "        )\n",
    "        train_processed = pd.read_csv(train_path)\n",
    "        test_processed = pd.read_csv(test_path)\n",
    "    else:\n",
    "        logger.info(\"Loading data from location: %s\", dataset_loc)\n",
    "        train_data, test_data = load_split_data(\n",
    "            str(dataset_loc), average_shots=average_shots\n",
    "        )\n",
    "        logger.info(\"Data loaded successfully.\")\n",
    "\n",
    "        logger.info(\"Initializing CustomSpectralPipeline.\")\n",
    "        pipeline = SVRCustomSpectralPipeline(\n",
    "            masks=masks,\n",
    "            composition_data_loc=composition_data_loc,\n",
    "            major_oxides=major_oxides,\n",
    "        )\n",
    "        logger.info(\"Pipeline initialized. Fitting and transforming data.\")\n",
    "        train_processed = pipeline.fit_transform(train_data)\n",
    "        test_processed = pipeline.fit_transform(test_data)\n",
    "        logger.info(\"Data processing complete.\")\n",
    "\n",
    "        preformatted_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        train_processed.to_csv(train_path, index=False)\n",
    "        test_processed.to_csv(test_path, index=False)\n",
    "\n",
    "    return train_processed, test_processed\n",
    "\n",
    "def load_and_scale_data(norm: int):\n",
    "    \"\"\"\n",
    "    Loads the data and scales it using the specified normalization method.\n",
    "    \"\"\"\n",
    "    train_processed, test_processed = load_data()\n",
    "\n",
    "    train_cols = train_processed.columns\n",
    "    test_cols = test_processed.columns\n",
    "\n",
    "    scaler = Norm1Scaler() if norm == 1 else Norm3Scaler()\n",
    "    train = scaler.fit_transform(train_processed)\n",
    "    test = scaler.fit_transform(test_processed)\n",
    "\n",
    "    # turn back into dataframe\n",
    "    train = pd.DataFrame(train, columns=train_cols)\n",
    "    test = pd.DataFrame(test, columns=test_cols)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def load_train_test_data(norm: int, drop_cols: list = [\"ID\", \"Sample Name\"]):\n",
    "    \"\"\"\n",
    "    Loads the train and test data and returns the X and y values.\n",
    "    \"\"\"\n",
    "    train, test = load_and_scale_data(norm)\n",
    "\n",
    "    # Converting train set\n",
    "    X_train = train.drop(columns=drop_cols)\n",
    "    y_train = train[major_oxides]\n",
    "\n",
    "    # Converting test set\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    y_test = test[major_oxides]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 3\n",
    "X_train, y_train, X_test, y_test = load_train_test_data(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(f'MAD_SVM_Norm{norm}_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "kernel=\"poly\"\n",
    "C=100\n",
    "eps=0.1\n",
    "gamma=\"scale\"\n",
    "degree=2\n",
    "coef0=1.0\n",
    "\n",
    "\n",
    "for target in y_train.columns:\n",
    "    print(target)\n",
    "    with mlflow.start_run(run_name=f\"MAD_SVM_{target}\"):\n",
    "        svm_reg = SVR(kernel=kernel, degree=degree, C=C, epsilon=eps, coef0=coef0, gamma=gamma)\n",
    "        print(f\"Training for {target}\")\n",
    "        print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train[target].shape}\")\n",
    "        svm_reg.fit(X_train, y_train[target])\n",
    "        print(f\"Predicting for {target}\")\n",
    "        y_pred = svm_reg.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test[target], y_pred))\n",
    "        mlflow.log_metric(\"rmse\", float(rmse))\n",
    "        mlflow.log_param(\"target\", target)\n",
    "        mlflow.log_param(\"norm\", norm)\n",
    "        mlflow.log_param(\"kernel\", kernel)\n",
    "        mlflow.log_param(\"degree\", degree)\n",
    "        mlflow.log_param(\"coef0\", coef0)\n",
    "        mlflow.log_param(\"C\", C)\n",
    "        mlflow.log_param(\"epsilon\", eps)\n",
    "        mlflow.log_param(\"gamma\", gamma)\n",
    "\n",
    "        models.append(svm_reg)\n",
    "        mlflow.sklearn.log_model(svm_reg, f\"model_{target}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

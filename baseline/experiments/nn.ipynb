{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lib import full_flow_dataloader\n",
    "\n",
    "# from config import logger\n",
    "from lib.norms import Norm1Scaler, Norm3Scaler\n",
    "\n",
    "train_processed, test_processed = full_flow_dataloader.load_full_flow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import mlflow.pytorch\n",
    "\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionNet, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(6144, 1024) # First layer\n",
    "        self.dropout1 = nn.Dropout(0.3)  # Dropout for regularization\n",
    "        self.fc2 = nn.Linear(1024, 512)  # Second layer\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(512, 256)   # Third layer\n",
    "        self.fc4 = nn.Linear(256, 128)   # Fourth layer\n",
    "        self.fc5 = nn.Linear(128, 8)     # Output layer with 8 variables\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x) # No activation, linear output\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = RegressionNet()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.reproduction import major_oxides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.epochs_no_improve = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.epochs_no_improve = 0\n",
    "        else:\n",
    "            self.epochs_no_improve += 1\n",
    "            if self.epochs_no_improve >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lib.utils import custom_train_test_split\n",
    "\n",
    "train_cols = train_processed.columns\n",
    "test_cols = test_processed.columns\n",
    "norm = 3\n",
    "\n",
    "scaler = (\n",
    "    Norm1Scaler()\n",
    "    if norm == 1\n",
    "    else \n",
    "    Norm3Scaler()\n",
    ")\n",
    "\n",
    "train = scaler.fit_transform(train_processed)\n",
    "test = scaler.fit_transform(test_processed)\n",
    "\n",
    "# turn back into dataframe\n",
    "train = pd.DataFrame(train, columns=train_cols)\n",
    "test = pd.DataFrame(test, columns=test_cols)\n",
    "\n",
    "split_train, split_val = custom_train_test_split(train, \"Sample Name\", test_size=0.2, random_state=42)\n",
    "\n",
    "drop_cols = major_oxides + [\"ID\", \"Sample Name\"]\n",
    "\n",
    "X_train = split_train.drop(columns=drop_cols).to_numpy()\n",
    "y_train = split_train[major_oxides].to_numpy()\n",
    "X_val = split_val.drop(columns=drop_cols).to_numpy()\n",
    "y_val = split_val[major_oxides].to_numpy()\n",
    "\n",
    "## SPLIT CONVENTIONAL\n",
    "# Splitting the training data into training and validation sets\n",
    "# X = train.drop(columns=drop_cols).to_numpy()\n",
    "# y = train[major_oxides].to_numpy()\n",
    "\n",
    "# Split ratio: 80% train, 20% validation\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting test set\n",
    "X_test = test.drop(columns=drop_cols).to_numpy()\n",
    "y_test = test[major_oxides].to_numpy()\n",
    "\n",
    "# Convert to tensors\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from datetime import datetime\n",
    "num_epochs = 10000\n",
    "batch_size = 32\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience=300, min_delta=0.01)\n",
    "\n",
    "mlflow.set_experiment(f'ANN_Norm{norm}_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "# Start an MLFlow run\n",
    "mlflow.start_run()\n",
    "\n",
    "# Log hyperparameters\n",
    "mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "mlflow.log_param(\"batch_size\", batch_size)\n",
    "# ... log other hyperparameters as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "    # Log metrics for each epoch\n",
    "    mlflow.log_metric('loss', loss.item(), step=epoch)\n",
    "    mlflow.log_metric('val_loss', val_loss.item(), step=epoch)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "    # Early stopping logic\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        mlflow.log_metric('early_stopping_epoch', epoch, step=epoch)\n",
    "        break\n",
    "\n",
    "# Log the model at the end of training\n",
    "mlflow.pytorch.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    loss = criterion(outputs, y_test)\n",
    "    print(f'Loss: {loss:.4f}')\n",
    "    \n",
    "    # Plot predictions vs actual\n",
    "    plt.scatter(y_test, outputs)\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the residuals\n",
    "    plt.scatter(y_test, y_test-outputs)\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Residual')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the residuals histogram\n",
    "    plt.hist(y_test-outputs)\n",
    "    plt.xlabel('Residual')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSEs\n",
    "rmse = np.sqrt(mean_squared_error(y_test, outputs))\n",
    "print(\"RMSE: \", rmse)\n",
    "mlflow.log_metric('rmse', float(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse for each oxide\n",
    "rmse_oxides = np.sqrt(mean_squared_error(y_true=y_test, y_pred=outputs, multioutput=\"raw_values\"))\n",
    "# as dataframe\n",
    "rmse_oxides = pd.DataFrame(rmse_oxides, index=major_oxides, columns=[\"RMSE\"])\n",
    "\n",
    "# log as metrics for each major oxide\n",
    "for oxide, rmse in rmse_oxides.iterrows():\n",
    "    mlflow.log_metric(f\"rmse_{oxide}\", rmse[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_oxides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper=5.3+1.03+3.47+2.31+2.21+2.72+0.62+0.82\n",
    "this=rmse_oxides.sum()\n",
    "\n",
    "(paper/8), round((sum(this)/8), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import datetime\n",
    "\n",
    "from lib.reproduction import major_oxides\n",
    "from lib.norms import Norm1Scaler, Norm3Scaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lib.get_preprocess_fn import get_preprocess_fn\n",
    "from lib.cross_validation import get_cross_validation_metrics, perform_cross_validation\n",
    "from lib.metrics import rmse_metric, std_dev_metric\n",
    "from experiments.optuna_run import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = major_oxides + [\"ID\", \"Sample Name\"]\n",
    "norm = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds, train, test = get_data(\"SiO2\")\n",
    "\n",
    "# Check for overlap between train and test on the column \"Sample Name\"\n",
    "overlap = set(train[\"Sample Name\"]).intersection(set(test[\"Sample Name\"]))\n",
    "if overlap:\n",
    "    raise ValueError(f\"Overlap detected ({len(overlap)}) between train and test on 'Sample Name': {overlap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "mlflow.set_experiment(f'RandomForest_Norm{norm}_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "\n",
    "for target in major_oxides:\n",
    "    folds, train, test = get_data(target)\n",
    "    with mlflow.start_run(run_name=f\"RandomForest_{target}\"):\n",
    "        # == Cross Validation ==\n",
    "        scaler = Norm1Scaler() if norm == 1 else Norm3Scaler()\n",
    "\n",
    "        cv_metrics = perform_cross_validation(\n",
    "            model=RandomForestRegressor(**params),\n",
    "            preprocess_fn=get_preprocess_fn(target_col=target, drop_cols=drop_cols, preprocessor=scaler),\n",
    "            folds=folds,\n",
    "            metric_fns=[rmse_metric, std_dev_metric],\n",
    "        )\n",
    "\n",
    "        mlflow.log_metrics(get_cross_validation_metrics(cv_metrics).as_dict())\n",
    "\n",
    "        # == Training ==\n",
    "        preprocess_fn = get_preprocess_fn(target_col=target, drop_cols=drop_cols, preprocessor=scaler)\n",
    "        X_train, y_train, X_test, y_test = preprocess_fn(train, test)\n",
    "\n",
    "        # Train the model\n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        models.append(model)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        rmse = rmse_metric(y_test, pred)\n",
    "        std_dev = std_dev_metric(y_test, pred)\n",
    "\n",
    "        # Logging\n",
    "        mlflow.log_params({\"target\": target, \"norm\": norm})\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"std_dev\": std_dev})\n",
    "        # mlflow.sklearn.log_model(model, f\"model_{target}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

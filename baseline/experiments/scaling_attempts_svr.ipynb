{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lib.full_flow_dataloader import load_full_flow_data\n",
    "from lib.reproduction import major_oxides\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler, StandardScaler, MaxAbsScaler, KernelCenterer\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel, sigmoid_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_full_flow_data()\n",
    "\n",
    "#robust_scaler = RobustScaler(quantile_range=(40, 60.0))\n",
    "#standard_scaler = StandardScaler()\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "power_scaler = PowerTransformer()\n",
    "#pca = PCA(n_components=34, whiten=True)\n",
    "pca = KernelPCA(n_components=60, kernel=\"cosine\")\n",
    "\n",
    "drop_cols = major_oxides + [\"ID\", \"Sample Name\"]\n",
    "\n",
    "# ---- train transformations ----\n",
    "X_train = train.drop(columns=drop_cols)\n",
    "y_train = train[major_oxides]\n",
    "\n",
    "#X_train = robust_scaler.fit_transform(X_train)\n",
    "#X_train = standard_scaler.fit_transform(X_train)\n",
    "X_train = max_abs_scaler.fit_transform(X_train)\n",
    "X_train = power_scaler.fit_transform(X_train)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "\n",
    "# ---- test transformations ---- \n",
    "X_test = test.drop(columns=drop_cols)\n",
    "y_test = test[major_oxides]\n",
    "\n",
    "#X_test = robust_scaler.transform(X_test)\n",
    "#X_test = standard_scaler.transform(X_test)\n",
    "X_test = max_abs_scaler.transform(X_test)\n",
    "X_test = power_scaler.transform(X_test)\n",
    "\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = pca.eigenvalues_\n",
    "explained_variance = eigenvalues / eigenvalues.sum()\n",
    "cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(cumulative_explained_variance)\n",
    "plt.xlabel('# PC')\n",
    "plt.xlim(0, 400)\n",
    "plt.ylabel('Explained variance')\n",
    "plt.title('Explained Variance by Number of Principal Components')\n",
    "plt.show()\n",
    "\n",
    "# --- Useful for calculating PC's for PCA\n",
    "#explained_variance = pca.explained_variance_ratio_\n",
    "#print(\"Explained variance:\", explained_variance)\n",
    "#cumulative_variance = np.cumsum(explained_variance)\n",
    "#print(\"Cumulative explained variance:\", cumulative_variance)\n",
    "#n_components = np.where(cumulative_variance >= 0.95)[0][0] + 1\n",
    "#print(\"Number of components to keep:\", n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "mlflow.set_experiment(f'Stacking_Scaler_SVR_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# disable warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "models = []\n",
    "\n",
    "kernel=\"poly\"\n",
    "C=100\n",
    "eps=0.1\n",
    "gamma=\"scale\"\n",
    "degree=2\n",
    "coef0=1.0\n",
    "\n",
    "xgb_params = {\n",
    "    \"max_depth\": 4,  # Slightly deeper trees since data is high-dimensional\n",
    "    \"min_child_weight\": 5,  # Higher to control over-fitting\n",
    "    \"gamma\": 0.1,  # Minimum loss reduction required to make further partition\n",
    "    \"subsample\": 0.7,  # Subsample ratio of the training instances\n",
    "    \"colsample_bytree\": 0.5,  # Subsample ratio of columns when constructing each tree\n",
    "    \"colsample_bylevel\": 0.5,  # Subsample ratio of columns for each level\n",
    "    \"colsample_bynode\": 0.5,  # Subsample ratio of columns for each split\n",
    "    \"lambda\": 1,  # L2 regularization term on weights (lambda)\n",
    "    \"alpha\": 0.5,  # L1 regularization term on weights (alpha)\n",
    "    \"learning_rate\": 0.05,  # Step size shrinkage used in update to prevent overfitting\n",
    "    \"n_estimators\": 100,  # Number of boosting rounds\n",
    "    \"objective\": \"reg:squarederror\",  # Regression with squared loss\n",
    "    \"eval_metric\": \"rmse\",  # Evaluation metric for validation data\n",
    "}\n",
    "\n",
    "for target in y_train.columns:\n",
    "    with mlflow.start_run(run_name=f\"SVR_{target}\"):\n",
    "        #estimator = XGBRegressor(**xgb_params)\n",
    "        #selector = RFECV(estimator, step=20, cv=KFold(5), scoring=\"neg_mean_squared_error\", verbose=1, n_jobs=-1)\n",
    "        #selector.fit(X_train, y_train[target])\n",
    "\n",
    "        #X_train_selected = selector.transform(X_train)\n",
    "        #X_test_selected = selector.transform(X_test)\n",
    "\n",
    "        svr_reg = SVR(kernel=kernel, degree=degree, C=C, epsilon=eps, coef0=coef0, gamma=gamma)\n",
    "        \n",
    "        svr_reg.fit(X_train, y_train[target])\n",
    "        y_pred = svr_reg.predict(X_test)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test[target], y_pred))\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", float(rmse))\n",
    "        mlflow.log_param(\"target\", target)\n",
    "        mlflow.log_param(\"kernel\", kernel)\n",
    "        mlflow.log_param(\"degree\", degree)\n",
    "        mlflow.log_param(\"coef0\", coef0)\n",
    "        mlflow.log_param(\"C\", C)\n",
    "        mlflow.log_param(\"epsilon\", eps)\n",
    "        mlflow.log_param(\"gamma\", gamma)\n",
    "\n",
    "        models.append(svr_reg)\n",
    "        mlflow.sklearn.log_model(svr_reg, f\"model_{target}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

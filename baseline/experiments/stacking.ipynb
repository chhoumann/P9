{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "from lib.full_flow_dataloader import load_full_flow_data\n",
    "from lib.reproduction import major_oxides\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, PowerTransformer, StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train: pd.DataFrame, test: pd.DataFrame) -> tuple:\n",
    "    drop_cols = major_oxides + [\"ID\", \"Sample Name\"]\n",
    "\n",
    "    X_train = train.drop(columns=drop_cols)\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    y_train = train[major_oxides]\n",
    "    y_test = test[major_oxides]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def preprocess_data(X_train: pd.DataFrame, X_test: pd.DataFrame, preprocesser_pipeline: Pipeline) -> tuple:\n",
    "    X_train = preprocesser_pipeline.fit_transform(X_train)\n",
    "    X_test = preprocesser_pipeline.transform(X_test)\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    model.add(layers.Reshape((48, 128, 1)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Additional convolutional block for better feature extraction\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(output_dim))\n",
    "\n",
    "    # Using L2 regularization\n",
    "    model.add(layers.Dense(output_dim, kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "    # Optimizer with a custom learning rate\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss=MeanSquaredError())\n",
    "    return model\n",
    "\n",
    "INPUT_DIM = 6144  # Number of features per sample\n",
    "OUTPUT_DIM = 1    # Number of continuous values as output\n",
    "\n",
    "cnn = KerasRegressor(build_fn=lambda: build_model(INPUT_DIM, OUTPUT_DIM), loss=MeanSquaredError() ,epochs=100, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio2_preprocessor_pipeline = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"power_transformer\", PowerTransformer())\n",
    "])\n",
    "\n",
    "tio2_preprocessor_pipeline = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"power_transformer\", PowerTransformer())\n",
    "])\n",
    "\n",
    "al203_preprocessor_pipeline = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"power_transformer\", PowerTransformer()),\n",
    "    (\"pca\", PCA(n_components=34))\n",
    "])\n",
    "\n",
    "feot_preprocessor_pipeline = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"power_transformer\", PowerTransformer()),\n",
    "])\n",
    "\n",
    "mgo_preprocessor_pipeline = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"power_transformer\", PowerTransformer()),\n",
    "    (\"kernel_pca\", KernelPCA(n_components=60, kernel=\"poly\"))\n",
    "])\n",
    "\n",
    "caot_preprocessor_pipeline = Pipeline([\n",
    "    (\"scaler\", RobustScaler(quantile_range=(10, 90))),\n",
    "    (\"power_transformer\", PowerTransformer()),\n",
    "    (\"kernel_pca\", KernelPCA(n_components=60, kernel=\"poly\"))\n",
    "])\n",
    "\n",
    "nao2_preprocessor_pipeline = Pipeline([\n",
    "    (\"scaler\", MaxAbsScaler()),\n",
    "    (\"power_transformer\", PowerTransformer()),\n",
    "])\n",
    "\n",
    "k2o_preprocessor_pipeline = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"power_transformer\", PowerTransformer()),\n",
    "])\n",
    "\n",
    "preprocessors = {\n",
    "    \"SiO2\": sio2_preprocessor_pipeline,\n",
    "    \"TiO2\": tio2_preprocessor_pipeline,\n",
    "    \"Al2O3\": al203_preprocessor_pipeline,\n",
    "    \"FeOT\": feot_preprocessor_pipeline,\n",
    "    \"MgO\": mgo_preprocessor_pipeline,\n",
    "    \"CaO\": caot_preprocessor_pipeline,\n",
    "    \"Na2O\": nao2_preprocessor_pipeline,\n",
    "    \"K2O\": k2o_preprocessor_pipeline\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimators = {\n",
    "    \"SiO2\": [\n",
    "        ('svr', SVR(kernel=\"poly\", C=100, epsilon=0.1, gamma=\"scale\", degree=2, coef0=1.0)),\n",
    "        ('etr', ExtraTreesRegressor(n_estimators=100, max_depth=None, min_samples_split=13, min_samples_leaf=14, max_features=0.5)),\n",
    "    ],\n",
    "    \"TiO2\": [\n",
    "        ('xgb', xgb.XGBRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.05,\n",
    "                objective=\"reg:squarederror\",\n",
    "                min_child_weight=5,\n",
    "                gamma=0.1,\n",
    "                subsample=0.7,\n",
    "                colsample_bytree=0.5,\n",
    "                colsample_bylevel=0.5,\n",
    "                colsample_bynode=0.5,\n",
    "                reg_lambda=1,\n",
    "                reg_alpha=0.5,\n",
    "                eval_metric=\"rmse\"\n",
    "            )\n",
    "        ),\n",
    "        ('pls', PLSRegression(n_components=5)),\n",
    "    ],\n",
    "    \"Al2O3\" : [\n",
    "        ('svr', SVR(kernel=\"poly\", C=100, epsilon=0.1, gamma=\"scale\", degree=2, coef0=1.0)),\n",
    "        ('xgb', xgb.XGBRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.05,\n",
    "                objective=\"reg:squarederror\",\n",
    "                min_child_weight=5,\n",
    "                gamma=0.1,\n",
    "                subsample=0.7,\n",
    "                colsample_bytree=0.5,\n",
    "                colsample_bylevel=0.5,\n",
    "                colsample_bynode=0.5,\n",
    "                reg_lambda=1,\n",
    "                reg_alpha=0.5,\n",
    "                eval_metric=\"rmse\"\n",
    "            )\n",
    "        ),\n",
    "        ('pls', PLSRegression(n_components=6)),\n",
    "    ],\n",
    "    \"FeOT\": [\n",
    "        ('gbr', GradientBoostingRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=3,\n",
    "                min_samples_split=2,\n",
    "                min_samples_leaf=1,\n",
    "                max_features=None,\n",
    "                loss='squared_error',\n",
    "                learning_rate=0.1,\n",
    "                subsample=1.0,\n",
    "                criterion='friedman_mse',\n",
    "                random_state=42,\n",
    "                verbose=0,\n",
    "                validation_fraction=0.1,\n",
    "                n_iter_no_change=None,\n",
    "                tol=1e-4,\n",
    "                ccp_alpha=0.0\n",
    "            )\n",
    "        ),\n",
    "        ('svr', SVR(kernel=\"poly\", C=100, epsilon=0.1, gamma=\"scale\", degree=2, coef0=1.0)),\n",
    "    ],\n",
    "    \"MgO\": [\n",
    "        ('gbr', GradientBoostingRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=3,\n",
    "                min_samples_split=2,\n",
    "                min_samples_leaf=1,\n",
    "                max_features=None,\n",
    "                loss='squared_error',\n",
    "                learning_rate=0.1,\n",
    "                subsample=1.0,\n",
    "                criterion='friedman_mse',\n",
    "                random_state=42,\n",
    "                verbose=0,\n",
    "                validation_fraction=0.1,\n",
    "                n_iter_no_change=None,\n",
    "                tol=1e-4,\n",
    "                ccp_alpha=0.0\n",
    "            )\n",
    "        ),\n",
    "        ('pls', PLSRegression(n_components=15)),\n",
    "        ('eln', ElasticNet(alpha=0.01, l1_ratio=0.3))\n",
    "    ],\n",
    "    \"CaO\": [\n",
    "        ('pls', PLSRegression(n_components=15)),\n",
    "        ('xgb', xgb.XGBRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.05,\n",
    "                objective=\"reg:squarederror\",\n",
    "                min_child_weight=5,\n",
    "                gamma=0.1,\n",
    "                subsample=0.7,\n",
    "                colsample_bytree=0.5,\n",
    "                colsample_bylevel=0.5,\n",
    "                colsample_bynode=0.5,\n",
    "                reg_lambda=1,\n",
    "                reg_alpha=0.5,\n",
    "                eval_metric=\"rmse\"\n",
    "            )\n",
    "        ),\n",
    "        ('svr', SVR(kernel=\"poly\", C=100, epsilon=0.1, gamma=\"scale\", degree=2, coef0=1.0)),\n",
    "    ],\n",
    "    \"Na2O\": [\n",
    "        ('svr', SVR(kernel=\"poly\", C=100, epsilon=0.1, gamma=\"scale\", degree=2, coef0=1.0)),\n",
    "        ('gbr', GradientBoostingRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=3,\n",
    "                min_samples_split=2,\n",
    "                min_samples_leaf=1,\n",
    "                max_features=None,\n",
    "                loss='squared_error',\n",
    "                learning_rate=0.1,\n",
    "                subsample=1.0,\n",
    "                criterion='friedman_mse',\n",
    "                random_state=42,\n",
    "                verbose=0,\n",
    "                validation_fraction=0.1,\n",
    "                n_iter_no_change=None,\n",
    "                tol=1e-4,\n",
    "                ccp_alpha=0.0\n",
    "            )\n",
    "        ),\n",
    "    ],\n",
    "    \"K2O\": [\n",
    "        ('svr', SVR(kernel=\"poly\", C=100, epsilon=0.1, gamma=\"scale\", degree=2, coef0=1.0)),\n",
    "        ('pls', PLSRegression(n_components=15)),\n",
    "        ('gbr', GradientBoostingRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=3,\n",
    "                min_samples_split=2,\n",
    "                min_samples_leaf=1,\n",
    "                max_features=None,\n",
    "                loss='squared_error',\n",
    "                learning_rate=0.1,\n",
    "                subsample=1.0,\n",
    "                criterion='friedman_mse',\n",
    "                random_state=42,\n",
    "                verbose=0,\n",
    "                validation_fraction=0.1,\n",
    "                n_iter_no_change=None,\n",
    "                tol=1e-4,\n",
    "                ccp_alpha=0.0\n",
    "            )\n",
    "        ),\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = SVR(kernel=\"poly\", C=100, epsilon=0.1, gamma=\"scale\", degree=2, coef0=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_full_flow_data()\n",
    "original_X_train, original_y_train, original_X_test, original_y_test = split_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_experiment(f'Stacking_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "y_preds = {}\n",
    "models = []\n",
    "\n",
    "for target in original_y_train.columns:\n",
    "    with mlflow.start_run(run_name=f\"Stacking_{target}\"):\n",
    "        X_train, X_test = original_X_train.copy(), original_X_test.copy()\n",
    "\n",
    "        current_preprocessor = preprocessors[target]\n",
    "        X_train, X_test = preprocess_data(X_train, X_test, current_preprocessor)\n",
    "\n",
    "        current_base_estimators = base_estimators[target]\n",
    "        stacking_regresor = StackingRegressor(estimators=current_base_estimators, final_estimator=meta_learner, cv=5)\n",
    "        stacking_regresor.fit(X_train, original_y_train[target])\n",
    "\n",
    "        y_pred = stacking_regresor.predict(X_test)\n",
    "        y_preds[target] = y_pred.tolist()\n",
    "\n",
    "        models.append(stacking_regresor)\n",
    "\n",
    "        actual_vs_predicted = {\"actual\": original_y_test[target], \"predicted\": y_pred}\n",
    "\n",
    "        rmse = mean_squared_error(original_y_test[target], y_pred, squared=False)\n",
    "        std_dev = np.std(original_y_test[target] - y_pred)\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", float(rmse))\n",
    "        mlflow.log_metric(\"std_dev\", float(std_dev))\n",
    "        mlflow.log_table(actual_vs_predicted, f\"actual_vs_predicted_{target}.json\")\n",
    "        mlflow.sklearn.log_model(stacking_regresor, f\"stacking_{target}\")\n",
    "\n",
    "        print(f\"RMSE for {target}: {rmse}\")\n",
    "        print(f\"Standard deviation for {target}: {std_dev}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

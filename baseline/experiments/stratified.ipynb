{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.cross_validation import (\n",
    "    StratifiedGroupKFoldSplit,\n",
    "    get_cross_validation_metrics,\n",
    "    perform_cross_validation,\n",
    ")\n",
    "from lib import full_flow_dataloader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from lib.reproduction import major_oxides\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full, test_full = full_flow_dataloader.load_full_flow_data(\n",
    "    load_cache_if_exits=True, average_shots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([train_full, test_full], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"MgO\"\n",
    "\n",
    "kf = StratifiedGroupKFoldSplit(n_splits=5, group_by=\"Sample Name\", random_state=42, target=target)\n",
    "train, test = kf.split(full_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kf = GroupKFold(n_splits=5)\n",
    "\n",
    "splits = list(plot_kf.split(full_data, groups=full_data[\"Sample Name\"]))\n",
    "\n",
    "# Make plotting code a function\n",
    "def plot_target_distribution(data, target, group_by, kf, n_cols=2):\n",
    "    splits = list(kf.split(data, groups=data[group_by]))\n",
    "    n_splits = len(splits)\n",
    "    n_rows = (n_splits + n_cols - 1) // n_cols  # Calculate the number of rows needed\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5))\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "    \n",
    "    for fold, (train_idx, _) in enumerate(splits):\n",
    "        train_fold = data.iloc[train_idx]\n",
    "        \n",
    "        # Plot the distribution of the target variable in the training set\n",
    "        ax = axes[fold]\n",
    "        ax.hist(train_fold[target], bins=20, alpha=0.7, label=f'Fold {fold + 1}')\n",
    "        ax.set_title(f'Distribution of Target in Fold {fold + 1}')\n",
    "        ax.set_xlabel('Target')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(fold + 1, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_target_distribution(full_data, target, \"Sample Name\", plot_kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of groups in train\n",
    "print(len(train[\"Sample Name\"].unique()))\n",
    "\n",
    "# number of groups in test\n",
    "print(len(test[\"Sample Name\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drop_cols = [\"ID\", \"Sample Name\"] + major_oxides\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "outliers = iso_forest.fit_predict(train.drop(drop_cols, axis=1))\n",
    "\n",
    "# print number of outliers\n",
    "print(np.sum(outliers == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of outliers\n",
    "print(np.sum(outliers == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of outliers\n",
    "# -1 means outlier, 1 means inlier\n",
    "plt.hist(outliers, bins=20)\n",
    "plt.title(\"Distribution of Outliers\")\n",
    "plt.xlabel(\"Outlier Label\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a heatmap of the outliers\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow([outliers], aspect=\"auto\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"Outliers in the Training Set\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Outlier Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "iso_forest_labels = iso_forest.fit_predict(train.drop(drop_cols, axis=1))\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "lof_labels = lof.fit_predict(train.drop(drop_cols, axis=1))\n",
    "\n",
    "outlier_labels = {\n",
    "    'iso_forest_labels': iso_forest_labels,\n",
    "    'lof_labels': lof_labels\n",
    "}\n",
    "\n",
    "combined_outlier_label = (outlier_labels['iso_forest_labels'] == -1) & (outlier_labels['lof_labels'] == -1)\n",
    "\n",
    "# print removed outliers\n",
    "print(np.sum(combined_outlier_label))\n",
    "\n",
    "# plot a heatmap of the outliers\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow([combined_outlier_label], aspect=\"auto\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"Outliers in the Training Set\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Outlier Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print samples that are outliers and only the sample column\n",
    "train[combined_outlier_label][\"Sample Name\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from lib.reproduction import major_oxides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lib.full_flow_dataloader import load_and_scale_data, load_full_flow_data\n",
    "from lib.utils import custom_train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler, PowerTransformer\n",
    "\n",
    "norm = 3\n",
    "\n",
    "# train, test = load_and_scale_data(norm)\n",
    "train, test = load_full_flow_data()\n",
    "\n",
    "drop_cols = major_oxides + [\"ID\", \"Sample Name\"]\n",
    "\n",
    "## - VALIDATION -\n",
    "# split_train, split_val = custom_train_test_split(train, \"Sample Name\", test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train = split_train.drop(columns=drop_cols)\n",
    "# y_train = split_train[major_oxides]\n",
    "# X_val = split_val.drop(columns=drop_cols)\n",
    "# y_val = split_val[major_oxides]\n",
    "\n",
    "\n",
    "# Initialize scalers\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "power_transformer = PowerTransformer()\n",
    "\n",
    "# Converting train set - comment out if using validation\n",
    "X_train = train.drop(columns=drop_cols)\n",
    "y_train = train[major_oxides]\n",
    "X_train = max_abs_scaler.fit_transform(X_train)\n",
    "X_train = power_transformer.fit_transform(X_train)\n",
    "\n",
    "# Converting test set\n",
    "X_test = test.drop(columns=drop_cols)\n",
    "y_test = test[major_oxides]\n",
    "X_test = max_abs_scaler.transform(X_test)\n",
    "X_test = power_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/22 12:17:33 INFO mlflow.tracking.fluent: Experiment with name 'SVM_poly_Norm3_20240422-121728' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "# disable warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "models = []\n",
    "\n",
    "kernel=\"poly\"\n",
    "C=100\n",
    "eps=0.1\n",
    "gamma=\"scale\"\n",
    "degree=2\n",
    "coef0=1.0\n",
    "\n",
    "mlflow.set_experiment(f'SVM_{kernel}_Norm{norm}_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "for target in y_train.columns:\n",
    "    with mlflow.start_run(run_name=f\"SVM_{target}\"):\n",
    "        svm_reg = SVR(kernel=kernel, degree=degree, C=C, epsilon=eps, coef0=coef0, gamma=gamma)\n",
    "        svm_reg.fit(X_train, y_train[target])\n",
    "\n",
    "        y_pred = svm_reg.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test[target], y_pred))\n",
    "        mlflow.log_metric(\"rmse\", float(rmse))\n",
    "        mlflow.log_param(\"target\", target)\n",
    "        mlflow.log_param(\"norm\", norm)\n",
    "        mlflow.log_param(\"kernel\", kernel)\n",
    "        mlflow.log_param(\"degree\", degree)\n",
    "        mlflow.log_param(\"coef0\", coef0)\n",
    "        mlflow.log_param(\"C\", C)\n",
    "        mlflow.log_param(\"epsilon\", eps)\n",
    "        mlflow.log_param(\"gamma\", gamma)\n",
    "\n",
    "        models.append(svm_reg)\n",
    "        mlflow.sklearn.log_model(svm_reg, f\"model_{target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from scipy.stats import expon\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# param_distributions = {\n",
    "#     \"pca__n_components\": [0.85, 0.90, 0.95, 0.99, 2, 5, 10, 15, 20],\n",
    "#     \"svr__kernel\": [\"poly\", \"rbf\", \"sigmoid\"],\n",
    "#     \"svr__C\": expon(scale=100),  # Continuous distribution for C\n",
    "#     \"svr__epsilon\": [0.1, 0.01, 0.001],\n",
    "#     \"svr__degree\": [2, 3, 4, 5],\n",
    "#     \"svr__coef0\": [0.0, 0.1, 0.5, 1.0],\n",
    "#     \"svr__gamma\": [\"scale\", \"auto\", 0.1, 0.01, 0.001],\n",
    "# }\n",
    "\n",
    "# # Setup RandomizedSearchCV\n",
    "# rscv = RandomizedSearchCV(\n",
    "#     estimator=make_pipeline(PCA(), SVR()),\n",
    "#     param_distributions=param_distributions,\n",
    "#     n_iter=100,\n",
    "#     cv=2,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# pca_models = []\n",
    "\n",
    "for target in y_train.columns:\n",
    "    with mlflow.start_run(run_name=f\"SVM_PCA_{target}\"):\n",
    "        rscv.fit(X_train, y_train[target])\n",
    "        best_estimator = rscv.best_estimator_\n",
    "\n",
    "        y_pred = best_estimator.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test[target], y_pred))\n",
    "        mlflow.log_metric(\"rmse\", float(rmse))\n",
    "\n",
    "        # log best params from grid search\n",
    "        mlflow.log_params(rscv.best_params_)\n",
    "        mlflow.log_param(\"target\", target)\n",
    "        mlflow.log_param(\"norm\", norm)\n",
    "\n",
    "#         pca_models.append(best_estimator)\n",
    "#         mlflow.sklearn.log_model(best_estimator, f\"model_{target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "experiments = mlflow.search_experiments()\n",
    "\n",
    "svm_norm_experiments = [exp for exp in experiments if exp.name.startswith(\"SVM_Norm\")]\n",
    "\n",
    "latest_experiment = sorted(\n",
    "    svm_norm_experiments,\n",
    "    key=lambda x: datetime.strptime(x.name.split('_')[-1], \"%Y%m%d-%H%M%S\"),\n",
    "    reverse=True\n",
    ")[0]\n",
    "\n",
    "runs = mlflow.search_runs([latest_experiment.experiment_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for _, row in runs.iterrows():\n",
    "    run_name = row['tags.mlflow.runName']\n",
    "    if run_name.startswith(\"SVM\") or run_name.startswith(\"SVM_PCA\"):\n",
    "        rmse = row['metrics.rmse']\n",
    "        with_pca = run_name.startswith(\"SVM_PCA\")\n",
    "        oxide_name = run_name.split('_')[1] if not with_pca else run_name.split('_')[2]\n",
    "        data.append({'Oxide': oxide_name, 'RMSE': rmse, 'WithPCA': with_pca})\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df = df.pivot_table(index='Oxide', columns='WithPCA', values='RMSE', aggfunc='first').rename(columns={True: 'With PCA', False: 'Without PCA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

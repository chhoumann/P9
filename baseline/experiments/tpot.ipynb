{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from lib.reproduction import major_oxides\n",
    "from lib import full_flow_dataloader\n",
    "from lib.norms import Norm1Scaler, Norm3Scaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed, test_processed = full_flow_dataloader.load_full_flow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lib.utils import custom_train_test_split\n",
    "\n",
    "train_cols = train_processed.columns\n",
    "test_cols = test_processed.columns\n",
    "norm = 1\n",
    "\n",
    "scaler = Norm1Scaler() if norm == 1 else Norm3Scaler()\n",
    "\n",
    "train = scaler.fit_transform(train_processed)\n",
    "test = scaler.fit_transform(test_processed)\n",
    "\n",
    "# turn back into dataframe\n",
    "train = pd.DataFrame(train, columns=train_cols)\n",
    "test = pd.DataFrame(test, columns=test_cols)\n",
    "\n",
    "drop_cols = major_oxides + [\"ID\", \"Sample Name\"]\n",
    "\n",
    "## - VALIDATION -\n",
    "# split_train, split_val = custom_train_test_split(train, \"Sample Name\", test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train = split_train.drop(columns=drop_cols)\n",
    "# y_train = split_train[major_oxides]\n",
    "# X_val = split_val.drop(columns=drop_cols)\n",
    "# y_val = split_val[major_oxides]\n",
    "\n",
    "# Converting train set - comment out if using validation\n",
    "X_train = train.drop(columns=drop_cols)\n",
    "y_train = train[major_oxides]\n",
    "\n",
    "# Converting test set\n",
    "X_test = test.drop(columns=drop_cols)\n",
    "y_test = test[major_oxides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                  \n",
      "Generation 1 - Current best internal CV score: -32.77342155019121\n",
      "                                                                                  \n",
      "Generation 2 - Current best internal CV score: -31.79131536902286\n",
      "                                                                                  \n",
      "Generation 3 - Current best internal CV score: -29.948997668204747\n",
      "                                                                                 \n",
      "Generation 4 - Current best internal CV score: -29.948997668204747\n",
      "                                                                                 \n",
      "Generation 5 - Current best internal CV score: -29.655941571927684\n",
      "                                                             \n",
      "Best pipeline: ExtraTreesRegressor(MaxAbsScaler(RidgeCV(MinMaxScaler(input_matrix))), bootstrap=True, max_features=0.35000000000000003, min_samples_leaf=19, min_samples_split=19, n_estimators=100)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error: Input data is not in a valid format. Please confirm that the input data is scikit-learn compatible. For example, the features must be a 2-D array and target labels must be a 1-D array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/p9/baseline/venv/lib/python3.10/site-packages/tpot/base.py:1388\u001b[0m, in \u001b[0;36mTPOTBase._check_dataset\u001b[0;34m(self, features, target, sample_weight)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1388\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imputed:\n",
      "File \u001b[0;32m~/projects/p9/baseline/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1279\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1264\u001b[0m     X,\n\u001b[1;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1277\u001b[0m )\n\u001b[0;32m-> 1279\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/projects/p9/baseline/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1300\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1299\u001b[0m estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m-> 1300\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1301\u001b[0m _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n",
      "File \u001b[0;32m~/projects/p9/baseline/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1367\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1369\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (390, 8) instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m oxide \u001b[38;5;129;01min\u001b[39;00m major_oxides:\n\u001b[1;32m      2\u001b[0m     tpot\u001b[38;5;241m.\u001b[39mfit(X_train, y_train[oxide])\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtpot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/p9/baseline/venv/lib/python3.10/site-packages/tpot/base.py:1092\u001b[0m, in \u001b[0;36mTPOTBase.score\u001b[0;34m(self, testing_features, testing_target)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted_pipeline_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1089\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA pipeline has not yet been optimized. Please call fit() first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m     )\n\u001b[0;32m-> 1092\u001b[0m testing_features, testing_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtesting_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1094\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;66;03m# If the scoring function is a string, we must adjust to use the sklearn\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# scoring interface\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring_function, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/projects/p9/baseline/venv/lib/python3.10/site-packages/tpot/base.py:1400\u001b[0m, in \u001b[0;36mTPOTBase._check_dataset\u001b[0;34m(self, features, target, sample_weight)\u001b[0m\n\u001b[1;32m   1398\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m features\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAssertionError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m-> 1400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Input data is not in a valid format. Please confirm \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1402\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat the input data is scikit-learn compatible. For example, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1403\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe features must be a 2-D array and target labels must be a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1404\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1-D array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1405\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Error: Input data is not in a valid format. Please confirm that the input data is scikit-learn compatible. For example, the features must be a 2-D array and target labels must be a 1-D array."
     ]
    }
   ],
   "source": [
    "for oxide in major_oxides:\n",
    "    tpot.fit(X_train, y_train[oxide])\n",
    "    print(tpot.score(X_test, y_test[oxide]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export(f\"tpot_{major_oxides[0]}_pipeline.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9426960700136946\n"
     ]
    }
   ],
   "source": [
    "# calculate rmse score for tpot\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "y_pred = tpot.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test[major_oxides[0]], y_pred))\n",
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

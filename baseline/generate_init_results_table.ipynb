{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "experiment_ids = [\n",
    "\t256, # ETR\n",
    "\t231, # Random Forest\n",
    "\t215, # Elastic Net,\n",
    "\t214, # Ridge\n",
    "\t210, # LASSO\n",
    "\t257, # ANN\n",
    "\t258, # CNN\n",
    "\t144, # NGB\n",
    "\t140, # PLS\n",
    "\t136, # XGBoost\n",
    "\t134, # SVR\n",
    "\t45, # GBR\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "\t\"Ridge\": \"Ridge\",\n",
    "\t\"LASSO\": \"\\\\gls{lasso}\",\n",
    "\t\"ElasticNet\": \"\\\\gls{enet}\",\n",
    "\t\"PLS\": \"\\\\gls{pls}\",\n",
    "\t\"SVR\": \"\\\\gls{svr}\",\n",
    "\t\"RandomForest\": \"\\\\gls{rf}\",\n",
    "\t\"NGB\": \"\\\\gls{ngboost}\",\n",
    "\t\"GBR\": \"\\\\gls{gbr}\",\n",
    "\t\"XGB\": \"\\\\gls{xgboost}\",\n",
    "\t\"ExtraTrees\": \"\\\\gls{etr}\",\n",
    "\t\"ANN\": \"\\\\gls{ann}\",\n",
    "\t\"CNN\": \"\\\\gls{cnn}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from lib.reproduction import major_oxides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "data = {}\n",
    "\n",
    "for experiment_id in experiment_ids:\n",
    "\tdata[experiment_id] = client.search_runs(experiment_id)\n",
    "\n",
    "data[experiment_ids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "model_means = {}\n",
    "\n",
    "# iterate over the data dictionary and print the runs\n",
    "for experiment_id, runs in data.items():\n",
    "    for run in runs:\n",
    "        # check if the target parameter is present\n",
    "        if \"target\" not in run.data.params:\n",
    "            continue\n",
    "\n",
    "        model_name = run.data.tags[\"mlflow.runName\"].split(\"_\")[0]\n",
    "        latex_name = model_name\n",
    "\n",
    "        if model_name in models:\n",
    "            latex_name = models[latex_name]\n",
    "\n",
    "        target = run.data.params[\"target\"]\n",
    "        rmse = run.data.metrics[\"rmse\"]\n",
    "        rmse_cv = run.data.metrics[\"rmse_cv\"]\n",
    "        std_dev = run.data.metrics[\"std_dev\"]\n",
    "        std_dev_cv = run.data.metrics[\"std_dev_cv\"]\n",
    "\n",
    "        print(f\"{model_name} - {target}, RMSE: {rmse}, RMSE CV: {rmse_cv}, STD DEV: {std_dev}, STD DEV CV: {std_dev_cv}\")\n",
    "\n",
    "        if model_name not in results:\n",
    "            results[model_name] = {}\n",
    "            model_means[model_name] = {\"rmse\": [], \"rmse_cv\": [], \"std_dev\": [], \"std_dev_cv\": []}\n",
    "\n",
    "        results[model_name][target] = {\n",
    "            \"latex_name\": latex_name,\n",
    "            \"rmse\": rmse,\n",
    "            \"rmse_cv\": rmse_cv,\n",
    "            \"std_dev\": std_dev,\n",
    "            \"std_dev_cv\": std_dev_cv,\n",
    "        }\n",
    "\n",
    "        # Collect metrics for calculating the mean\n",
    "        model_means[model_name][\"rmse\"].append(rmse)\n",
    "        model_means[model_name][\"rmse_cv\"].append(rmse_cv)\n",
    "        model_means[model_name][\"std_dev\"].append(std_dev)\n",
    "        model_means[model_name][\"std_dev_cv\"].append(std_dev_cv)\n",
    "\n",
    "# Calculate means\n",
    "for model_name, metrics in model_means.items():\n",
    "    model_means[model_name] = {\n",
    "        \"rmse\": np.mean(metrics[\"rmse\"]),\n",
    "        \"rmse_cv\": np.mean(metrics[\"rmse_cv\"]),\n",
    "        \"std_dev\": np.mean(metrics[\"std_dev\"]),\n",
    "        \"std_dev_cv\": np.mean(metrics[\"std_dev_cv\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "latex_table = \"\\\\begin{table*}[]\\n\"\n",
    "latex_table += \"\\\\centering\\n\"\n",
    "latex_table += \"\\\\resizebox{1\\\\textwidth}{!}{%\\n\"\n",
    "latex_table += \"\\\\begin{tabular}{l|cccc|cccc|cccc}\\n\"\n",
    "\n",
    "model_keys = list(models.keys())\n",
    "\n",
    "for i in range(0, len(model_keys), 3):\n",
    "    chunk = model_keys[i:i+3]\n",
    "\n",
    "    # Header row\n",
    "    header_row = \"Model\"\n",
    "    for model in chunk:\n",
    "        header_row += f\" & \\\\multicolumn{{4}}{{c}}{{{models[model]}}}\"\n",
    "\n",
    "    latex_table += header_row + \" \\\\\\\\\\n\"\n",
    "\n",
    "    # Metric row\n",
    "    metric_row = \"Metric\"\n",
    "    for _ in chunk:\n",
    "        metric_row += \" & \\\\multicolumn{1}{c}{RMSEP} & \\\\multicolumn{1}{c}{RMSECV} & \\\\multicolumn{1}{c}{Std. dev.} & \\\\multicolumn{1}{c}{Std. dev. CV}\"\n",
    "\n",
    "    latex_table += metric_row + \" \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "    # Data rows\n",
    "    for target in major_oxides:\n",
    "        row = f\"$\\\\ce{{{target}}}$\"\n",
    "\n",
    "        for model in chunk:\n",
    "            if model in results and target in results[model]:\n",
    "                metrics = results[model][target]\n",
    "                row += f\" & {metrics['rmse']:.4f} & {metrics['rmse_cv']:.4f} & {metrics['std_dev']:.4f} & {metrics['std_dev_cv']:.4f}\"\n",
    "            else:\n",
    "                print(f\"Missing data for {model} - {target}\")\n",
    "                row += \" & - & - & - & -\"\n",
    "\n",
    "        latex_table += row + \" \\\\\\\\\\n\"\n",
    "\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "    # Mean rows\n",
    "    mean_row = \"Mean\"\n",
    "    for model in chunk:\n",
    "        if model in model_means:\n",
    "            mean_metrics = model_means[model]\n",
    "            mean_row += f\" & {mean_metrics['rmse']:.4f} & {mean_metrics['rmse_cv']:.4f} & {mean_metrics['std_dev']:.4f} & {mean_metrics['std_dev_cv']:.4f}\"\n",
    "        else:\n",
    "            mean_row += \" & - & - & - & -\"\n",
    "\n",
    "    latex_table += mean_row + \" \\\\\\\\\\n\"\n",
    "    latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "latex_table += \"\\\\end{tabular}%\\n\"\n",
    "latex_table += \"}\\n\"\n",
    "latex_table += \"\\\\caption{Initial results for the different models and metrics.}\\n\"\n",
    "latex_table += \"\\\\end{table*}\\n\"\n",
    "\n",
    "# Write the LaTeX table string to a file\n",
    "path = Path(\"./../report_thesis/src/sections/results/init_results_table.tex\")\n",
    "\n",
    "with open(path, \"w\") as file:\n",
    "    file.write(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

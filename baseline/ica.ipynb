{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    "\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from numpy.linalg import eig, pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_input(X_input, num_sources=None, verbose=True):\n",
    "    # Check if X is a NumPy ndarray\n",
    "    assert isinstance(X_input, np.ndarray), \\\n",
    "        \"X (input data matrix) is of the wrong type (%s)\" % type(X_input)\n",
    "    \n",
    "    # Remember the original data type of X\n",
    "    input_data_type = X_input.dtype\n",
    "\n",
    "    # Convert X to a NumPy matrix of type float64\n",
    "    X_input = np.matrix(X_input.astype(np.float64))\n",
    "\n",
    "    # Check if X is a 2-dimensional matrix\n",
    "    assert X_input.ndim == 2, \"X_input has %d dimensions, should be 2\" % X_input.ndim\n",
    "    \n",
    "    # Check if the verbose parameter is either True or False\n",
    "    assert isinstance(verbose, bool), \\\n",
    "        \"verbose parameter should be either True or False\"\n",
    "\n",
    "    # Get the number of input signals (num_signals (n)) and number of samples (num_samples (T))\n",
    "    num_signals, num_samples = X_input.shape\n",
    "\n",
    "    # Set the number of sources to the number of sensors if not specified\n",
    "    if num_sources is None:\n",
    "        num_sources = num_signals\n",
    "    # Check if the number of sources does not exceed the number of sensors\n",
    "    assert num_sources <= num_signals, \\\n",
    "        \"jade -> Do not ask more sources (%d) than sensors (%d) here!!!\" % (num_sources, num_signals)\n",
    "\n",
    "    # Verbose output\n",
    "    if verbose:\n",
    "        print(\"jade -> Looking for \" + str(num_sources) + \" sources\")\n",
    "        print(\"jade -> Removing the mean value\")\n",
    "    \n",
    "    # Remove the mean value from X\n",
    "    X_input -= X_input.mean(1)\n",
    "\n",
    "    return X_input, input_data_type, num_sources, num_samples\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_PCA_and_whitening(preprocessed_data, num_components, num_signals, num_samples, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform Principal Component Analysis (PCA) and whitening on the given preprocessed data.\n",
    "\n",
    "    Parameters:\n",
    "    preprocessed_data (numpy.matrix): The data matrix after preprocessing.\n",
    "    num_components (int): The number of principal components to extract.\n",
    "    num_signals (int): The total number of signals in the data.\n",
    "    num_samples (int): The number of samples in each signal.\n",
    "    verbose (bool): If True, additional information is printed.\n",
    "\n",
    "    Returns:\n",
    "    numpy.matrix: The matrix of principal components. Each column is a principal component.\n",
    "    numpy.array: The array of sorted eigenvalues corresponding to the principal components.\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"jade -> Whitening the data\")\n",
    "\n",
    "    # Compute the covariance matrix of the whitened data\n",
    "    covariance_matrix = (preprocessed_data * preprocessed_data.T) / float(num_samples)\n",
    "\n",
    "    # Perform eigenvalue decomposition to find the principal components\n",
    "    eigenvalues, eigenvectors = eig(covariance_matrix)\n",
    "\n",
    "    # Sort eigenvalues in descending order\n",
    "    sorted_indices = eigenvalues.argsort()[::-1]\n",
    "    sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "\n",
    "    # Extract the principal components corresponding to the most significant eigenvalues\n",
    "    principal_components = eigenvectors[:, sorted_indices[:num_components]]\n",
    "\n",
    "    # Transpose the matrix so each row represents a principal component\n",
    "    principal_components = principal_components.T\n",
    "\n",
    "    return principal_components, sorted_eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_cumulant_matrices_storage(num_components):\n",
    "    \"\"\"\n",
    "    Initialize the storage for cumulant matrices.\n",
    "\n",
    "    Parameters:\n",
    "    num_components (int): Number of principal components.\n",
    "\n",
    "    Returns:\n",
    "    numpy.matrix: Initialized matrix for storing cumulant matrices.\n",
    "    int: Number of cumulant matrices.\n",
    "    \"\"\"\n",
    "    dim_symmetric_matrices = (num_components * (num_components + 1)) / 2\n",
    "    num_cumulant_matrices = int(dim_symmetric_matrices)\n",
    "    cumulant_matrices_storage = np.matrix(np.zeros([num_components, num_components * num_cumulant_matrices], dtype=np.float64))\n",
    "\n",
    "    return cumulant_matrices_storage, num_cumulant_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cumulant_matrix(preprocessed_data, num_samples, component_index, num_cumulant_matrices):\n",
    "    \"\"\"\n",
    "    Compute an individual cumulant matrix for a given component.\n",
    "\n",
    "    Parameters:\n",
    "    preprocessed_data (numpy.matrix): Transposed preprocessed data matrix.\n",
    "    num_samples (int): Number of samples in each signal.\n",
    "    component_index (int): Index of the current component.\n",
    "    num_cumulant_matrices (int): Total number of cumulant matrices.\n",
    "\n",
    "    Returns:\n",
    "    numpy.matrix: The computed cumulant matrix for the given component.\n",
    "    \"\"\"\n",
    "    component_signal = preprocessed_data[:, component_index]\n",
    "    component_signal_squared = np.multiply(component_signal, component_signal)\n",
    "    cumulant_matrix = np.multiply(component_signal_squared, preprocessed_data).T * preprocessed_data / float(num_samples)\n",
    "\n",
    "    return cumulant_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_diagonalization(num_components, num_cumulant_matrices):\n",
    "    \"\"\"\n",
    "    Initialize matrices and variables for the diagonalization process.\n",
    "\n",
    "    Parameters:\n",
    "    num_components (int): Number of principal components.\n",
    "    num_cumulant_matrices (int): Total number of cumulant matrices.\n",
    "\n",
    "    Returns:\n",
    "    Tuple containing:\n",
    "        - rotation_matrix (numpy.matrix): Matrix for joint diagonalization.\n",
    "        - diagonal_values (numpy.array): Diagonal values array.\n",
    "        - on_diagonal (float): Sum of squared diagonal elements.\n",
    "        - off_diagonal (float): Sum of squared off-diagonal elements.\n",
    "    \"\"\"\n",
    "    rotation_matrix = np.matrix(np.eye(num_components, dtype=np.float64))\n",
    "    on_diagonal = 0.0\n",
    "    off_diagonal = 0.0\n",
    "\n",
    "    return rotation_matrix, on_diagonal, off_diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_diagonalization(cumulant_matrices_storage, num_components, num_cumulant_matrices, num_samples):\n",
    "    \"\"\"\n",
    "    Perform joint diagonalization on the cumulant matrices.\n",
    "\n",
    "    Parameters:\n",
    "    cumulant_matrices_storage (numpy.matrix): Storage matrix containing cumulant matrices.\n",
    "    num_components (int): Number of principal components.\n",
    "    num_cumulant_matrices (int): Total number of cumulant matrices.\n",
    "    num_samples (int): Number of samples in each signal.\n",
    "\n",
    "    Returns:\n",
    "    numpy.matrix: The diagonalized matrix.\n",
    "    \"\"\"\n",
    "    rotation_matrix, on_diagonal, off_diagonal = initialize_diagonalization(num_components, num_cumulant_matrices)\n",
    "\n",
    "    threshold = 1.0e-6 / np.sqrt(num_samples)\n",
    "    encore = True\n",
    "    sweep = 0\n",
    "    updates = 0\n",
    "\n",
    "    while encore:\n",
    "        encore = False\n",
    "        sweep += 1\n",
    "        upds = 0\n",
    "\n",
    "        for p in range(num_components - 1):\n",
    "            for q in range(p + 1, num_components):\n",
    "\n",
    "                Ip = np.arange(p, num_components * num_cumulant_matrices, num_components)\n",
    "                Iq = np.arange(q, num_components * num_cumulant_matrices, num_components)\n",
    "\n",
    "                # Compute Givens angles\n",
    "                g = np.concatenate([cumulant_matrices_storage[p, Ip] - cumulant_matrices_storage[q, Iq], \n",
    "                                    cumulant_matrices_storage[p, Iq] + cumulant_matrices_storage[q, Ip]])\n",
    "                gg = np.dot(g, g.T)\n",
    "                ton = gg[0, 0] - gg[1, 1]\n",
    "                toff = gg[0, 1] + gg[1, 0]\n",
    "                theta = 0.5 * np.arctan2(toff, ton + np.sqrt(ton * ton + toff * toff))\n",
    "                Gain = (np.sqrt(ton * ton + toff * toff) - ton) / 4.0\n",
    "\n",
    "                # Givens update\n",
    "                if abs(theta) > threshold:\n",
    "                    encore = True\n",
    "                    upds += 1\n",
    "                    c = np.cos(theta)\n",
    "                    s = np.sin(theta)\n",
    "                    G = np.matrix([[c, -s], [s, c]])\n",
    "                    pair = np.array([p, q])\n",
    "\n",
    "                    rotation_matrix[:, pair] *= G\n",
    "                    cumulant_matrices_storage[pair, :] = G.T * cumulant_matrices_storage[pair, :]\n",
    "                    cumulant_matrices_storage[:, np.concatenate([Ip, Iq])] = \\\n",
    "                        np.append(c * cumulant_matrices_storage[:, Ip] + s * cumulant_matrices_storage[:, Iq], \n",
    "                                  -s * cumulant_matrices_storage[:, Ip] + c * cumulant_matrices_storage[:, Iq], axis=1)\n",
    "                    on_diagonal += Gain\n",
    "                    off_diagonal -= Gain\n",
    "\n",
    "        updates += upds\n",
    "\n",
    "    return rotation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_separating_matrix(separating_matrix):\n",
    "    \"\"\"\n",
    "    Sort the rows of the separating matrix based on the energy of the components.\n",
    "\n",
    "    Parameters:\n",
    "    separating_matrix (numpy.matrix): The separating matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy.matrix: Sorted separating matrix.\n",
    "    \"\"\"\n",
    "    mixing_matrix = np.linalg.pinv(separating_matrix)\n",
    "    energy_order = np.argsort(np.sum(np.multiply(mixing_matrix, mixing_matrix), axis=0))[::-1]\n",
    "    sorted_matrix = separating_matrix[energy_order, :]\n",
    "\n",
    "    return sorted_matrix[::-1, :]  # Reverse to have the most energetic components first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_matrix_signs(separating_matrix):\n",
    "    \"\"\"\n",
    "    Adjust the signs of the rows of the separating matrix.\n",
    "\n",
    "    Parameters:\n",
    "    separating_matrix (numpy.matrix): The separating matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy.matrix: The separating matrix with adjusted signs.\n",
    "    \"\"\"\n",
    "    for i in range(separating_matrix.shape[0]):\n",
    "        if np.sign(separating_matrix[i, 0]) == -1 or np.sign(separating_matrix[i, 0]) == 0:\n",
    "            separating_matrix[i, :] *= -1\n",
    "            \n",
    "    return separating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jadeR(mixed_signal_matrix, num_components=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "\n",
    "        mixed_signal_matrix -- an nxT data matrix (n sensors, T samples). May be a numpy array or\n",
    "             matrix.\n",
    "\n",
    "        num_components -- output matrix B has size mxn so that only m sources are\n",
    "             extracted.  This is done by restricting the operation of jadeR\n",
    "             to the m first principal components. Defaults to None, in which\n",
    "             case m=n.\n",
    "\n",
    "        verbose -- print info on progress. Default is True.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        An m*n matrix B (NumPy matrix type), such that Y=B*X are separated\n",
    "        sources extracted from the n*T data matrix X. If m is omitted, B is a\n",
    "        square n*n matrix (as many sources as sensors). The rows of B are\n",
    "        ordered such that the columns of pinv(B) are in order of decreasing\n",
    "        norm; this has the effect that the `most energetically significant`\n",
    "        components appear first in the rows of Y=B*X.\n",
    "    \"\"\"\n",
    "\n",
    "    # GB: we do some checking of the input arguments and copy data to new\n",
    "    # variables to avoid messing with the original input. We also require double\n",
    "    # precision (float64) and a numpy matrix type for preprocessed_data.\n",
    "\n",
    "    # Original code had: X, origtype, m, n, T\n",
    "\n",
    "\n",
    "    preprocessed_data, input_data_type, num_components, num_samples = check_input(mixed_signal_matrix, num_components, verbose)\n",
    "\n",
    "    # whitening & PCA\n",
    "    principal_components, sorted_eigenvalues = perform_PCA_and_whitening(preprocessed_data, num_components, num_samples, verbose)\n",
    "\n",
    "    \n",
    "    # Scaling\n",
    "    # Calculate the scaling factors for the principal components.\n",
    "    # The scaling factor for each principal component is the inverse of the square root of its corresponding eigenvalue.\n",
    "    # This normalization ensures that each principal component has unit variance.\n",
    "    scaling_factors = np.sqrt(sorted_eigenvalues[:num_components])  # Calculate square roots of top eigenvalues\n",
    "    whitening_matrix = np.diag(1. / scaling_factors) * principal_components.T  # Create whitening matrix by inverting the scaling factors\n",
    "\n",
    "    # Sphering (Whitening)\n",
    "    # Apply the whitening transformation to the preprocessed data.\n",
    "    # This step transforms the data such that the resulting components are uncorrelated and each has unit variance.\n",
    "    # The transformation is achieved by multiplying the whitening matrix with the preprocessed data.\n",
    "    sphered_data = whitening_matrix * preprocessed_data  # Transform the data to a whitened space\n",
    "\n",
    "    # Clean up by deleting variables that are no longer needed to free up memory\n",
    "    del sorted_eigenvalues, principal_components, scaling_factors\n",
    "\n",
    "    if verbose:\n",
    "        print(\"jade -> Estimating cumulant matrices\")\n",
    "\n",
    "    # Initialize the storage for cumulant matrices\n",
    "    cumulant_matrices_storage, num_cumulant_matrices = initialize_cumulant_matrices_storage(num_components)\n",
    "    \n",
    "    # Compute and store cumulant matrices\n",
    "    for component_index in range(num_components):\n",
    "        cumulant_matrix = compute_cumulant_matrix(preprocessed_data.T, num_samples, component_index, num_cumulant_matrices)\n",
    "        # Store the computed cumulant matrix in the appropriate location\n",
    "        storage_start_index = component_index * num_components\n",
    "        storage_end_index = storage_start_index + num_components\n",
    "        cumulant_matrices_storage[:, storage_start_index:storage_end_index] = cumulant_matrix\n",
    "\n",
    "\n",
    "    rotation_matrix = joint_diagonalization(cumulant_matrices_storage, num_components, num_cumulant_matrices, num_samples)\n",
    "\n",
    "    separating_matrix = rotation_matrix.T * whitening_matrix\n",
    "\n",
    "    # Apply the sorting and sign fixing\n",
    "    if verbose:\n",
    "        print(\"jade -> Sorting the components\")\n",
    "    separating_matrix = sort_separating_matrix(separating_matrix)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"jade -> Fixing the signs\")\n",
    "    separating_matrix = fix_matrix_signs(separating_matrix)\n",
    "\n",
    "    return separating_matrix.astype(input_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JADE:\n",
    "    def __init__(self, num_components=4):\n",
    "        self.num_components = num_components\n",
    "        self.unmixing_matrix = None\n",
    "        self.ica_jade_loadings = None\n",
    "        self.ica_jade_corr = None\n",
    "        self.ica_jade_ids = None\n",
    "\n",
    "    def fit(self, mixed_signal_matrix):\n",
    "        \"\"\"\n",
    "        Fit the JADE model to the data.\n",
    "\n",
    "        Parameters:\n",
    "        mixed_signal_matrix (numpy.ndarray): The mixed signal data matrix.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: The unmixing matrix after applying JADE.\n",
    "        \"\"\"\n",
    "        mixed_signal_matrix = np.array(mixed_signal_matrix)\n",
    "        unmixing_matrix = jadeR(mixed_signal_matrix, m=self.num_components)\n",
    "\n",
    "        # Adjust the sign of each row for better interpretability\n",
    "        for i in range(unmixing_matrix.shape[0]):\n",
    "            if np.abs(np.max(unmixing_matrix[i, :])) < np.abs(np.min(unmixing_matrix[i, :])):\n",
    "                unmixing_matrix[i, :] *= -1\n",
    "\n",
    "        self.unmixing_matrix = unmixing_matrix\n",
    "        return unmixing_matrix\n",
    "\n",
    "    def transform(self, mixed_signal_matrix):\n",
    "        \"\"\"\n",
    "        Transform the data using the learned JADE model.\n",
    "\n",
    "        Parameters:\n",
    "        mixed_signal_matrix (numpy.ndarray): The mixed signal data matrix.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: The separated signals.\n",
    "        \"\"\"\n",
    "        if self.unmixing_matrix is None:\n",
    "            raise ValueError(\"Model has not been fit yet. Call 'fit' with training data.\")\n",
    "\n",
    "        return np.dot(self.unmixing_matrix, mixed_signal_matrix.T).T\n",
    "\n",
    "    def correlate_loadings(self, df, corrcols, icacols):\n",
    "        \"\"\"\n",
    "        Find the correlation between loadings and a set of columns.\n",
    "\n",
    "        Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame containing data.\n",
    "        corrcols (list): List of columns to correlate.\n",
    "        icacols (list): List of ICA columns.\n",
    "\n",
    "        Updates:\n",
    "        self.ica_jade_corr: DataFrame of correlations.\n",
    "        self.ica_jade_ids: Identifiers for the correlated loadings.\n",
    "        \"\"\"\n",
    "        if self.unmixing_matrix is None:\n",
    "            raise ValueError(\"Model has not been fit yet. Call 'fit' with training data.\")\n",
    "\n",
    "        corrdf = df.corr().drop(icacols, axis=1).drop(corrcols, axis=0)\n",
    "        ica_jade_ids = []\n",
    "        for i in corrdf.loc['ICA-JADE'].index:\n",
    "            tmp = corrdf.loc[('ICA-JADE', i)]\n",
    "            max_corr = np.max(tmp)\n",
    "            match = tmp.values == max_corr\n",
    "            matched_col = corrcols[np.where(match)[0][0]]\n",
    "            ica_jade_ids.append(f\"{matched_col} (r={np.round(max_corr, 1)})\")\n",
    "\n",
    "        self.ica_jade_corr = corrdf\n",
    "        self.ica_jade_ids = ica_jade_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

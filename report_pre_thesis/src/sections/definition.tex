\section{Definition}\label{sec:definition}
Let $D$ be the LIBS data set, defined in the space $\Lambda \times \mathbb{R}^m$, where $\Lambda$ represents the set of possible wavelengths and $\mathbb{R}^m$ denotes the $m$-dimensional space of intensities.
The dataset $D$ is given by:

\begin{equation}
    D = \{ (\lambda_1, \vec{I}_1), (\lambda_2, \vec{I}_2), \ldots, (\lambda_n, \vec{I}_n) \}
\end{equation}

Each element $(\lambda_i, \vec{I}_i) \in \Lambda \times \mathbb{R}^{m}$ comprises the wavelength $\lambda_i$ of the $i^{th}$ measurement point, measured in nanometers, and an $m$-dimensional intensity vector $\vec{I}_i = [I_{i1}, I_{i2}, \ldots, I_{im}]$.
This vector captures the intensity values at $\lambda_i$ for each of the $m$ shots, measured in units of photons per channel.

Given a set of major oxides $E$ where $k=|E|$, define a model $M$ that learns a hypothesis function $f: \Lambda \times \mathbb{R}^m \rightarrow \mathbb{R}^k$ to predict the composition of the $k$ major oxides in geological samples.
The output of the hypothesis function is a vector $\mathbf{\hat{y}} = [o_{1}, o_{2}, \ldots, o_{8}]$ where $o_{i}$ is the predicted value of the weight percentage of the $i^{th}$ major oxide.
The sum of the predicted weight percentages is not necessarily equal to 100\%.
The samples may contain other elements that are not considered major oxides, which would account for the difference.
If the sum of the predicted weight percentages is greater than 100\%, the model is overestimating the weight percentages, and represents a physical impossibility.

We introduce a general error function $g$ that quantifies the disparity between predicted weight percentages $\mathbf{\hat{y}}$ and the true weight percentages $\mathbf{y}$:

\begin{equation}
g: \mathbb{R}^k \times \mathbb{R}^k \rightarrow \mathbb{R}^+
\end{equation}

where $g(\mathbf{\hat{y}}, \mathbf{y})$ denotes the magnitude of error between the two vectors.
The precise form of $g$ can vary based on the specific metric chosen to measure the difference. The function $g$ serves as a benchmark to assess the model's predictive accuracy.


Let $C$ be the set of components that comprise the model $M$.
Each component $c_j \in C$ is responsible for a specific task in predicting the composition of major oxides in geological samples.
The overall error $E$ of the model \( M \) is quantified by the loss function \( g \) as:

\[
E = g(\mathbf{\hat{y}}, \mathbf{y})
\]

To measure the contribution of each component \( c_j \) to this overall error, we introduce a term \( \Delta g_j \) which is defined as:

\[
\Delta g_j = g(\mathbf{\hat{y}}, \mathbf{y}) - g(F_j(\mathbf{\hat{y}}), F_j(\mathbf{y}))
\]

Here, \( F_j(\mathbf{\hat{y}}) \) and \( F_j(\mathbf{y}) \) are the predicted and true vectors with the influence of component \( c_j \) controlled for. To control for \( c_j \), we modify it in a way that neutralizes its effect on the overall prediction, thereby isolating its contribution to the overall error.
Then, we aim to address the following problem in this work:

\textbf{Problem:} For each component \( c_j \in C \), calculate \( \Delta g_j \) to quantify its contribution to the overall error \( g(\mathbf{\hat{y}}, \mathbf{y}) \). Subsequently, rank the components in order of their \( \Delta g_j \) values to identify the most critical elements affecting the model's predictive accuracy.

In the next paragraphs, we provide insights into the specific components of the MOC model and their respective tasks in predicting the composition of major oxides in geological samples.


% In this work, we aim to identify and propose improvements to the specific components of the current MOC model that limit its predictive accuracy and robustness against matrix effects.
% We have a model which is comprised of various components. Each component contributes to the overall error in some way.
% By identifying the specific components that contribute the most to the overall error, we can focus our efforts on improving these components.
% In order to figure out which components contribute the most to the overall error, we need to be able to measure the error of each component.
% To some extent, some components can be isolated while others have a high degree of interdependence.

% First, we have to create a baseline to compare against - this would be a reproduction of the current MOC model.
% The next step is to perform different experiments (ablation study, hyperparameter tuning, pre-processing, normalization, ensemble models etc.).
% The goal is to measure the effect of each experiment on the overall error.
% These experiments serve as an indirect measure of the contribution of each component to the error.
% Each experiment will only affect a localized subset of the components.
% By measuring the effect of each experiment on the overall error, we can infer the contribution of each component to the overall error.
% The inference is based on the assumption that the components that are most affected by the experiments are the ones that contribute the most to the overall error.
% We can then rank the components in order of their contribution to the overall error.
% The components that contribute the most to the overall error are the ones that we should focus on improving.
% We can then propose improvements to these components and measure the effect of these improvements on the overall error.
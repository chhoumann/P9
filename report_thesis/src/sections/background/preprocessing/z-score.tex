\subsubsection{Z-Score Standardization}
Z-Score Standardization, also known as zero-mean normalization, transforms data to have a mean of zero and a standard deviation of one.
This technique is useful when the actual minimum and maximum of a feature are unknown or when outliers may significantly skew the distribution.
The Z-Score Standardization of a feature vector \(\mathbf{x}\) is given by:

$$
x'_i = \frac{x_i - \overline{\mathbf{x}}}{\sigma_\mathbf{x}},
$$

where \(x_i\) is the original value, \(\overline{\mathbf{x}}\) is the mean of the feature vector \(\mathbf{x}\), \(\sigma_\mathbf{x}\) is the standard deviation of the feature vector \(\mathbf{x}\), and \(x'_i\) is the normalized feature value.
By transforming the data using the Z-score, each value reflects its distance from the mean in terms of standard deviations.
Z-Score Standardization is particularly advantageous in scenarios where data features have different units or scales, or when preparing data for algorithms that assume normally distributed inputs~\cite{dataminingConcepts}.

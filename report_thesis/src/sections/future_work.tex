\section{Future Work}\label{sec:future_work}
The findings of this study open several avenues for future research.
Firstly, for our data partitioning algorithm, described in Section~\ref{subsubsec:dataset_partitioning}, we noted that finding the optimal percentile value $p$ that minimizes extreme values in the test set, while maintaining its general representativeness, is important.
Future work should consider methods of quantitatively assesing and finding this value.
Such methods could include supplementary extreme value testing to the data partitioning algorithm, where after the primary evaluation, additional testing is conducted using a small, separate subset of extreme values to assess the model's performance on these critical cases.
For example, this could involve slightly reducing the percentile value $p$ and using the extreme values that fall within this reduced range to evaluate the model.

Another point of interest is limited data availability.
The small dataset size naturally limits the amount of how many extreme values are present.
These extreme values are an essential part of improving the model's generalizability, as they are the most challenging cases to predict.
Future work should investigate methods of augmenting the dataset with synthetic extreme value data to provide the model with more exposure to these cases during training.

Future work should also consider further experimentation with the choices of base estimators and meta-learners.
Our study highlighted that multiple model and preprocessor configurations perform well.
However, determining which configurations and meta-learner is optimal for a given oxide is a challenging task.
In this study, we used a simple grouping to ensure diversity in our base estimator selection, chosen from the top-performing configurations.
This approach could be improved upon by, for example, developing more advanced selection methods that consider the base estimators and meta-learners in conjunction. 
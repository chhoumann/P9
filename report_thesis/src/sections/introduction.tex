\section{Introduction}\label{sec:introduction}
NASA has been studying the Martian environment for decades through a series of missions, including the Viking missions~\cite{marsnasagov_vikings}, the \gls{mer} mission~\cite{marsnasagov_observer, marsnasagov_spirit_opportunity}, and the \gls{msl} mission~\cite{marsnasagov_msl}, each building on the knowledge gained from the previous ones.
Today, the rovers exploring Mars are equipped with sophisticated instruments for analyzing the chemical composition of Martian soil in search of past life and habitable environments.

Part of this research is facilitated through interpretation of spectral data gathered by \gls{libs} instruments, which fire a high-powered laser at soil samples to create a plasma.
The emitted light is captured by spectrometers and analyzed using machine learning models to assess the presence and concentration of certain major oxides, informing NASA's understanding of Mars' geology~\cite{cleggRecalibrationMarsScience2017}.

However, predicting major oxide compositions from \gls{libs} data still presents significant computational challenges.
These include the high dimensionality and non-linearity of the data, compounded by issues of multicollinearity and matrix effects~\cite{andersonImprovedAccuracyQuantitative2017}.
Such effects can cause the intensity of emission lines from an element to vary independently of that element's concentration, introducing unknown variables that complicate the analysis.
Furthermore, the high cost of data collection often results in small datasets, exacerbating the difficulty of building accurate and robust models.

Previous work has aimed to improve the prediction of major oxide compositions from \gls{libs} data by using regression techniques and dimensionality reduction with feature selection.
These methods have been used to enhance both the accuracy and interpretability of the prediction models.
Tailored approaches have also been developed, where different models are selected based on their performance with specific spectral characteristics~\cite{rezaei_dimensionality_reduction, andersonPostlandingMajorElement2022}.
Moreover, models incorporating physical principles have demonstrated improved accuracy by handling residuals that traditional models fail to explain~\cite{song_DF-K-ELM}.
However, predicting oxide compositions remains challenging due to the complex, nonlinear nature of \gls{libs} data.
This underscores the need for continued research into more adaptive and robust machine learning strategies to tackle these issues effectively.

This thesis aims to improve upon previous work in the field of \gls{libs} data analysis.
Our goal is to develop a machine learning pipeline that is tailored to the unique characteristics of \gls{libs} data, with the goal of achieving higher prediction accuracy and robustness.

To achieve these objectives, we build upon the baseline established in~\cite{p9_paper} and systematically explore ten different machine learning models.
These models were identified and selected through a combination of extensive literature review and the consideration of unconventional approaches not typically covered in the \gls{libs}-based calibration literature.
The ten models fall into three categories: Ensemble learning models, linear and regularization models, and neural network models.
In addition to model exploration, we also investigate a selection of preprocessing techniques: scaling (including normalization), dimensionality reduction, and data transformation.
Specifically, we designed and implemented a framework for experimental analysis using the automated hyperparameter optimization framework Optuna~\cite{optuna_2019}.
We then used this framework to determine the most effective combinations of preprocessing methods and models for each regression target.
We began by identifying the most promising models from the literature, after which we evaluated various preprocessing techniques to understand their impact on model performance, selecting those that demonstrated the highest impact on improving the performance of each model.
Following this, we optimized the chosen models along with various preprocessors, using our hyperparameter optimization framework, to ensure optimal performance tailored to the specific data characteristics of each oxide.

As a result, we have developed a comprehensive catalog of models and preprocessing techniques that can be used to predict major oxide compositions in \gls{libs} data.
This catalog features configurations of various preprocessing methods and machine learning models for each of the eight major oxides examined in this study, all of which have demonstrated high effectiveness.
Additionally, to investigate the potential for further performance enhancement, we used the developed catalog to experiment with stacking ensemble using the best performing configurations for each oxide and three different meta-learners.
Though limited in scope, this approach demonstrated improved performance of approximately 24\%-34\% over baseline \gls{rmsep}.

Our key contributions are as follows:
\begin{itemize}
    \item We have developed a comprehensive catalog of machine learning models and preprocessing techniques for predicting major oxide compositions in \gls{libs} data. This catalog presents highly effective configurations of several preprocessing methods and machine learning models for each of the eight major oxides examined in this study, allowing for a more informed selection of models and preprocessing techniques in future work.
    \item We have contributed directly to the development of \gls{pyhat}, a Python-based toolset by \gls{usgs} for machine learning and data analysis on hyperspectral data. Our work has been integrated into the toolset, further enhancing its capabilities for the scientific community.
\end{itemize}

The remainder of this paper is organized as follows:
In Section~\ref{sec:related-work}, we review the related work on quantitative analysis in the field of \gls{libs} data analysis.
Section~\ref{sec:problem_definition} formally defines the problem addressed in this work.
Section~\ref{sec:background} provides an overview of the data used in this work, the preprocessing techniques, and the machine learning models and techniques employed in our proposed pipeline.
In Section~\ref{sec:baseline_replica}, we present a brief introduction to the \gls{moc} model and our previous work on replicating it. The results are used as a baseline comparison for our stacking ensemble.
Section~\ref{sec:proposed_approach} introduces our proposed approach to addressing the problem definition, including model and preprocessing selection, data partitioning and cross-validation strategy, and our optimization framework.
Section~\ref{sec:methodology} details our experimental design and presents the results of the experiments conducted in this work, including those of our stacking ensemble.
Finally, Section~\ref{sec:future_work} and Section~\ref{sec:future_work} conclude the paper by summarizing our findings, discussing the implications of our work, and giving suggestions for future work, respectively.

Due to the overlapping nature of terminology used in \gls{libs} data analysis and machine learning, we provide a list of terms in Table~\ref{tab:terms} to clarify their meaning.

\begin{table}
\centering
\begin{tabularx}{\columnwidth}{lX} % l for left, X for the cell that should be wrapped
\toprule
Term & Definition \\
\midrule
Sample & A physical specimen of rock, soil, or other material collected for scientific analysis.\\
Location & The specific point on a sample where a LIBS laser is targeted. There are typically multiple locations per sample. \\
Target & Refers to the variable that a machine learning model is trained to predict. \\
Extreme Concentration Values & The concentration values of oxides in the targets that are significantly higher or lower than the majority of the data. \\
\bottomrule
\end{tabularx}
\caption{Table of Terms}
\label{tab:terms}
\end{table}
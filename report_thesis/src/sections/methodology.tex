\section{Methodology}\label{sec:methodology}
\textit{We will write an introduction to the methodology section here, as well as add more subsections in the future. Below is the first subsection describing the data normalization process and the reasons for choosing to only do Norm 3. Please let us know if the explanation and mathematical notation is clear.}

\subsection{Evaluation Metrics}
To evaluate the performance of our models in predicting major oxide compositions from \gls{libs} data, we will use two key metrics: \gls{rmse} and standard deviation of prediction errors.

\gls{rmse} will be used as a measure of accuracy, quantifying the difference between the predicted and actual values of the major oxides in the samples. It is defined by the equation:

\begin{equation}
    RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2},
\end{equation}

where $y_i$ represents the actual values, $\hat{y}_i$ the predicted values, and $n$ the number of observations. A lower RMSE indicates better accuracy.

To assess the robustness of our models, we will consider the standard deviation of prediction errors across each oxide and test instance. This metric measures the variability of the prediction errors and provides insight into the consistency of the model's performance. It is defined as:

\begin{equation}
    \sigma_{error} = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (e_i - \bar{e})^2},
\end{equation}

where $e_i = y_i - \hat{y}_i$ and $\bar{e}$ is the mean error. A lower standard deviation indicates better robustness.

By using these two metrics, we aim to evaluate model performance in terms of both accuracy and robustness, which are crucial for the reliable prediction of major oxide compositions from \gls{libs} data.

\subsection{Experiment}
To determine the best model for predicting major oxide compositions from \gls{libs} data, we conducted a series of experiments using various machine learning algorithms.
We started with a wide range of models and gradually narrowed down to the top-performing ones.
Then, we researched these models in more detail to identify the best configuration for each oxide.

The experiments were conducted using a funnel approach, where we started with a broad set of models and progressively focused on those whose performance showed the most promise using the aforementioned evaluation metrics.
Based on the results from the litterature outlined in Section~\ref{sec:related-work}, we selected the most promising models for our experiments:
\begin{itemize}
    \item \gls{svr}
    \item \gls{gbr}
    \item \gls{xgboost}
    \item \gls{pls} Regression
    \item \gls{cnn}
    \item \gls{ann}
    \item \gls{enet}
\end{itemize}



% - Short introduction to the experiments section outlining the approach
%     - Found a bunch of related litterature first related to LIBS, preprocessing and machine learning
%     - Led to the decision to conduct a wide range of experiments to find the best model for our data
% - Funnel approach
%     - Start with a wide range of models
%     - Narrow down to the best 4 models
%     - Research these models in more detail
% - For data preprocessing, examined which methods worked the best for these select models
%     - Normalization, feature selection (variance threshold), autoencoders, etc.
%     - Narrowed down to different transformations and normalization methods (i.e. PowerTransformer and RobustScaler)
% - Experimented with ensemble methods
%     - Boosting and stacking
%     - Found that stacking was the best method
% - Use Optuna to find the best configuration for each oxide, including:
%     - architecture
%     - hyperparameters
%     - data preprocessing

\section{Methodology}\label{sec:methodology}
In this section, we outline the methodology used in this study to address the challenges identified in the problem definition. Our objective was to identify the most promising machine learning models and preprocessing techniques proposed from the literature, as outlined in Section~\ref{sec:related-work}, for predicting major oxide compositions from LIBS data. 
Then, using this knowledge, develop a pipeline that utilizes the strengths of these models and preprocessing techniques to improve prediction accuracy and robustness of the predictions.
We first describe the datasets used, including their preparation and the method of splitting for model training. Next, we outline the preprocessing steps and the model selection process, followed by a detailed explanation of the experimental setup and evaluation metrics. Finally, we discuss our validation testing procedures and the approach taken to ensure unbiased final model evaluations.

\subsection{Data Prepraration}
Similarly to our previous work \cite{p9_paper}, we used the publicly available \gls{ccs} data. 
\gls{ccs} refers to \gls{libs} data that has been through a series of preprocessing steps such as subtracting the ambient light background, noise removal and removing the electron continuum to derive data that is more suitable for quantitative analysis. 
The full description of this preprocessing can be found in \citet{wiensPreFlight3}.

While the CCS data is in a more suitable form for quantitative analysis, it still requires further preprocessing. Specifically, the data are still noisy at the spectrometer edges, and this noise has to be masked out. The data also contains negative values, which are not physically meaningful and need to be zeroed out.
For a more detailed description of the data and the preprocessing steps, we refer the reader to \citet{p9_paper}, as data preparation follows the same procedure detailed in that work.

Once preprocessed, the data was conventionally split into training and testing sets. 
As detailed in \citet{p9_paper} and \citet{cleggRecalibrationMarsScience2017}, it is essential to include samples with extreme element compositions in the training set to ensure the model can generalize effectively.
To incorporate these extreme values, the training set was constructed to include the two highest and two lowest samples from each oxide category.
Following the inclusion of extreme samples, we adjusted the size of the test split to accommodate the reduced pool of normal samples. 
This adjustment was calculated by determining the number of extreme samples, subtracting this from the total sample count, and recalculating the test size proportionally. 
This ensures that the proportion of the test set remains appropriate relative to the now smaller dataset. 
Subsequently, we conducted the train-test split, where the normal samples --- those not categorized as extreme --- were divided according to the newly adjusted test size, with the extreme samples included to ensure exposure to varied data points.

\subsection{Model and Preprocessing Selection}
For the initial investigative experiments, we selected a range of models for further exploration, namely \gls{svr}, \gls{gbr}, \gls{pls}, \gls{xgboost}, \gls{ngboost}, \gls{etr}, \gls{enet}, and \gls{sgd}.
We also included regular neural network (NN) and convolutional neural networks (CNN) in this phase of experimentation. 
This selection was guided primarily by the literature review but also by exploratory intuition,
aiming to discover potentially innovative applications and performances within our specific dataset.

Our literature review highlighted various approaches and their effectiveness in handling the challenges associated with predicting major oxide compositions from LIBS data. 
For instance, Anderson et al. discussed the use of multiple regression models, finding that different models excelled with specific oxides, which informed our model-specific approach. 
Song et al. presented a hybrid model combining domain knowledge with machine learning, which inspired our interest in models that could offer both high performance and interpretability. Rezaei et al. demonstrated the beneficial impact of dimensionality reduction techniques like PCA, which we considered essential for managing our high-dimensional LIBS data.

All models demonstrated robust performance; however, \gls{gbr}, \gls{svr}, \gls{xgboost}, \gls{etr}, and \gls{pls} consistently excelled across all oxides. 
Notably, we observed model-specific strengths for certain oxidesâ€”SVR was particularly effective for \ce{SiO2}, while \gls{gbr} excelled with \ce{FeO_T}. 
This differential performance prompted us to explore architectural frameworks that could systematically capitalize on the strengths of each model for specific oxides.

A particularly exciting discovery from our literature review was a study on the stacking and chaining of normalization methods initially aimed at classification contexts. 
Inspired by these ideas, we explored the possibility of improving model performance by optimizing the preprocessing chain for each model, per oxide, in order to determine which normalization methods would be most beneficial.
For this purpose, we considered the following preprocessing techniques: Min-Max Scaling, Standard Scaling, Robust Scaling, MaxAbs Scaling, Quantile Transformer and Power Transformer. 
Additionally, we also considered dimensionality reduction techniques such as PCA and KernelPCA.
Through experimentation, we identified which preprocessing techniques were most effective for each model and oxide. 
Realizing the potential of this, we decided to further investigate how the predictive accuracy and robustness could be improved by combining the strengths of these models and preprocessing techniques.
From our investigation, we determined that the stacking ensemble method seemed very promising and novel in the LIBS analysis field, leading us to select it as the primary method for our study.

Stacking ensemble is analogous to the methodologies employed in the original MOC pipeline, which also tailored predictions for each oxide by blending outputs from the PLS-SM and ICA phases, variably weighting the influence of the ICA predictions depending on the oxide.
Unlike the MOC model, which required manual determination of the model weightings for each oxide, our method utilizes a meta learner to learn optimal parameter settings. 
Stacking ensemble is beneficial as it dynamically adapts to our dataset's characteristics without the need for domain-specific knowledge.
This approach represents a more sophisticated method, streamlining complex model configurations and potentially enhancing predictive accuracy through dynamically learned integrations, rather than fixed presets.

\subsection{Experimental Setup}

\subsection{Validation and Testing Procedures}


\subsection{Summary}

\section{Methodology}\label{sec:methodology}
\textit{We will write an introduction to the methodology section here, as well as add more subsections in the future. Below is the first subsection describing the data normalization process and the reasons for choosing to only do Norm 3. Please let us know if the explanation and mathematical notation is clear.}

\subsection{Evaluation Metrics}
To evaluate the performance of our models in predicting major oxide compositions from \gls{libs} data, we will use two key metrics: \gls{rmse} and standard deviation of prediction errors.

\gls{rmse} will be used as a measure of accuracy, quantifying the difference between the predicted and actual values of the major oxides in the samples. It is defined by the equation:

\begin{equation}
    RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2},
\end{equation}

where $y_i$ represents the actual values, $\hat{y}_i$ the predicted values, and $n$ the number of observations. A lower RMSE indicates better accuracy.

To assess the robustness of our models, we will consider the standard deviation of prediction errors across each oxide and test instance. This metric measures the variability of the prediction errors and provides insight into the consistency of the model's performance. It is defined as:

\begin{equation}
    \sigma_{error} = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (e_i - \bar{e})^2},
\end{equation}

where $e_i = y_i - \hat{y}_i$ and $\bar{e}$ is the mean error. A lower standard deviation indicates better robustness.

By using these two metrics, we aim to evaluate model performance in terms of both accuracy and robustness, which are crucial for the reliable prediction of major oxide compositions from \gls{libs} data.

\subsection{Experiments}
To address the objectives of this study described in the problem definition in Section~\ref{sec:???}, we adopted an experimental approach.
The initial phase of the project was dedicated to identifying the current state of the art in machine learning methodologies and reviewing recent literature specifically on LIBS data analysis.
Based on our findings, we tested various methodologies on our data.
This allowed us to identify and focus on the models that performed best and were most relevant to our specific dataset.

Drawing from the related literature and initial experimentation, we selected the following models for further investigation: \gls{svr}, \gls{gbr}, \gls{pls}, \gls{xgboost}, \gls{ngboost}, \gls{etr}, \gls{enet}, and \gls{sgd}.
This selection was partly guided by conventional criteria and partly by exploratory intuition, aiming to discover potentially innovative applications and performances within our specific dataset.

All models demonstrated robust performance; however, \gls{gbr}, \gls{svr}, \gls{xgboost}, \gls{etr}, and \gls{pls} consistently excelled across all oxides.
Notably, we observed model-specific strengths for certain oxidesâ€”\gls{svr} was particularly effective for \ce{SiO2}, while \gls{gbr} excelled with \ce{FeO_T}.
This differential performance prompted us to explore architectural frameworks that could systematically capitalize on the strengths of each model for specific oxides.
Consequently, we concluded that a stacking ensemble method would optimize outcomes for our dataset.
This approach is analogous to the methodologies employed in the original MOC pipeline, which also tailored predictions for each oxide by blending outputs from the PLS-SM and ICA phases, variably weighting the influence of the ICA predictions depending on the oxide.
However, unlike the MOC model, which required manual determination of the model weightings for each oxide, our stacking approach utilizes a meta learner.
This meta learner learns optimal parameter settings, ensuring that the model integration is not only more efficient but also dynamically adapted to our dataset's characteristics and does not require domain-specific knowledge.
This represents a more sophisticated method, as it automates critical decisions and enhances predictive accuracy through learned rather than preset integrations.

In this section, we present the experiments conducted, the results obtained, and the architecture of the final model, which utilizes the proposed stacking ensemble method.

% - Short introduction to the experiments section outlining the approach
%     - Found a bunch of related litterature first related to LIBS, preprocessing and machine learning
%     - Led to the decision to conduct a wide range of experiments to find the best model for our data
% - Funnel approach
%     - Start with a wide range of models
%     - Narrow down to the best 4 models
%     - Research these models in more detail
% - For data preprocessing, examined which methods worked the best for these select models
%     - Normalization, feature selection (variance threshold), autoencoders, etc.
%     - Narrowed down to different transformations and normalization methods (i.e. PowerTransformer and RobustScaler)
% - Experimented with ensemble methods
%     - Boosting and stacking
%     - Found that stacking was the best method
% - Use Optuna to find the best configuration for each oxide, including:
%     - architecture
%     - hyperparameters
%     - data preprocessing

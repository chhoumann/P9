This section details the parameter ranges used for various preprocessing techniques and models in our Optuna optimization framework.
Our aim is to explore a wide range of preprocessing techniques and model combinations to identify the best-performing configurations for use in the stacking ensemble.

For preprocessing, we include a range of parameters for various transformers and scalars, as shown in Table~\ref{tab:optuna_model_configurations}.
The goal is to explore both conventionally used and novel preprocessing techniques with a wide range of parameters to maximize coverage while avoiding excessive search space expansion.
For instance, the number of components for \gls{pca} (1-50) and \gls{kernel-pca} (1-100) ensures essential feature capture while balancing computational load.
Flexibility is provided by including various categorical choices and numerical ranges, such as different kernel types in \gls{kernel-pca}, and logarithmic scales for gamma values ($10^{-3}$ to $10^{1}$), allowing models to adapt to diverse data characteristics.
Efficiency is maintained by using logarithmic scales for parameters that span several orders of magnitude, optimizing the search process.
Scaler parameters, such as the quantile ranges in \texttt{RobustScaler}, are designed to accommodate different data distributions.
Similarly, the transformation methods in \texttt{PowerTransformer} and \texttt{QuantileTransformer} are selected to handle a variety of data distributions.

\begin{table*}[h]
\centering
\begin{tabular}{@{}l>{\ttfamily}lp{0.5\textwidth}@{}}
\toprule
\textbf{Model}                       & \textbf{Parameter}                & \textbf{Range}                           \\ \midrule
\multirow{2}{*}{PCA}                 & n\_components                     & 1 - 50                                   \\ \cmidrule{2-3}
                                     & whiten                            & \{True, False\}                          \\ \midrule
\multirow{4}{*}{KernelPCA}           & n\_components                     & 1 - 100                                  \\ \cmidrule{2-3}
                                     & kernel                            & \{linear, poly, rbf, sigmoid, cosine\}   \\ \cmidrule{2-3}
                                     & gamma                             & $10^{-3}$ - $10^{1}$ (log scale)         \\ \cmidrule{2-3}
                                     & degree                            & 1 - 5                                    \\ \midrule
\multirow{2}{*}{RobustScaler}        & quantile\_range                   & \{25-75, 10-90, 5-95, 35-65, 30-70, 40-60\} \\ \cmidrule{2-3}
                                     & with\_centering                   & \{True, False\}                          \\ \midrule
\multirow{2}{*}{StandardScaler}      & with\_mean                        & \{True, False\}                          \\ \cmidrule{2-3}
                                     & with\_std                         & \{True, False\}                          \\ \midrule
MinMaxScaler                         & feature\_range                    & \{0,1\}, \{-1,1\}                        \\ \midrule
\multirow{2}{*}{PowerTransformer}    & method                            & yeo-johnson                              \\ \cmidrule{2-3}
                                     & standardize                       & \{True, False\}                          \\ \midrule
\multirow{3}{*}{QuantileTransformer} & n\_quantiles                      & 100 - 1000                               \\ \cmidrule{2-3}
                                     & output\_distribution              & \{uniform, normal\}                      \\ \cmidrule{2-3}
                                     & subsample                         & 10000 - 100000                           \\ \midrule
MaxAbsScaler                         & -                                 & -                                        \\ \midrule
Norm3Scaler                          & -                                 & -                                        \\ \midrule
\end{tabular}
\label{tab:optuna_model_configurations}
\caption{Optuna preprocessing configuration ranges.}
\end{table*}


For the models, we include a range of parameters for various regressors, as shown in Table~\ref{tab:optuna_model_configurations}.
Similar to the preprocessing parameters, we aim to cover a wide range of regressors and their respective hyperparameters while maintaining a balance between coverage and computational efficiency.
Parameters like the number of estimators for \gls{gbr} and \gls{xgboost} (100-1000) provide flexibility in controlling the model complexity and training duration.
The learning rate parameter, ranging from $10^{-3}$ to $10^{0}$ in logarithmic scale, allows fine-tuning of the model's convergence speed and accuracy.
Maximum depth settings for tree-based models (\gls{gbr}, \gls{xgboost}, \gls{rf}, and \gls{etr}) range from 2 to 15, ensuring sufficient depth to capture complex patterns while avoiding overfitting.
Moreover, the inclusion of different kernel types for \gls{svr} (linear, poly, rbf, sigmoid) and the use of logarithmic scales for parameters such as \texttt{C}, \texttt{epsilon}, and \texttt{gamma}, help in adapting the models to various data characteristics and distributions.
The parameter ranges are chosen to span multiple orders of magnitude, such as the regularization parameters \texttt{alpha} in \gls{lasso}, \gls{ridge}, and \gls{enet}, which range from $10^{-3}$ to $10^{3}$.


\begin{table*}[h]
\centering
\begin{tabular}{@{}l>{\ttfamily}lp{0.5\textwidth}@{}}
\toprule
\textbf{Model}                 & \textbf{Parameter}          & \textbf{Range}                           \\ \midrule
\multirow{5}{*}{\gls{gbr}}     & n\_estimators               & 100 - 1000                                \\ \cmidrule{2-3}
                               & learning\_rate              & $10^{-3}$ - $10^{0}$ (log scale)          \\ \cmidrule{2-3}
                               & max\_depth                  & 3 - 10                                    \\ \cmidrule{2-3}
                               & subsample                   & 0.5 - 1.0                                 \\ \cmidrule{2-3}
                               & max\_features               & \{sqrt, log2\}                            \\ \midrule
\multirow{6}{*}{\gls{svr}}     & C                           & $10^{-3}$ - $10^{3}$ (log scale)          \\ \cmidrule{2-3}
                               & epsilon                     & $10^{-3}$ - $10^{1}$ (log scale)          \\ \cmidrule{2-3}
                               & kernel                      & \{linear, poly, rbf, sigmoid\}            \\ \cmidrule{2-3}
                               & degree                      & 1 - 5                                     \\ \cmidrule{2-3}
                               & gamma                       & \{scale, auto\}                           \\ \cmidrule{2-3}
                               & coef0                       & 0 - 10                                    \\ \midrule
\multirow{8}{*}{\gls{xgboost}} & n\_estimators               & 100 - 1000                                \\ \cmidrule{2-3}
                               & learning\_rate              & $10^{-3}$ - $10^{0}$ (log scale)          \\ \cmidrule{2-3}
                               & max\_depth                  & 2 - 15                                    \\ \cmidrule{2-3}
                               & subsample                   & 0.3 - 1.0                                 \\ \cmidrule{2-3}
                               & colsample\_bytree           & 0.5 - 1.0                                 \\ \cmidrule{2-3}
                               & gamma                       & $10^{-3}$ - $10^{1}$ (log scale)          \\ \cmidrule{2-3}
                               & reg\_alpha                  & $10^{-3}$ - $10^{3}$ (log scale)          \\ \cmidrule{2-3}
                               & reg\_lambda                 & $10^{-3}$ - $10^{3}$ (log scale)          \\ \midrule
\multirow{5}{*}{\gls{etr}}     & n\_estimators               & 100 - 1000                                \\ \cmidrule{2-3}
                               & max\_depth                  & 2 - 15                                    \\ \cmidrule{2-3}
                               & min\_samples\_split         & 2 - 20                                    \\ \cmidrule{2-3}
                               & min\_samples\_leaf          & 1 - 25                                    \\ \cmidrule{2-3}
                               & max\_features               & \{sqrt, log2\}                            \\ \midrule
PLS                            & n\_components               & 1 - 30                                    \\ \midrule
\multirow{8}{*}{\gls{ngboost}} & max\_depth                  & 2 - 10                                    \\ \cmidrule{2-3}
                               & natural\_gradient           & \{True, False\}                           \\ \cmidrule{2-3}
                               & n\_estimators               & 50 - 1000                                 \\ \cmidrule{2-3}
                               & learning\_rate              & 0.01 - 0.5 (log scale)                    \\ \cmidrule{2-3}
                               & minibatch\_frac             & 0.5 - 1.0                                 \\ \cmidrule{2-3}
                               & col\_sample                 & 0.5 - 1.0                                 \\ \cmidrule{2-3}
                               & tol                         & $10^{-5}$ - $10^{-3}$ (log scale)         \\ \cmidrule{2-3}
                               & validation\_fraction        & 0.1 - 0.5                                 \\ \cmidrule{2-3}
                               & early\_stopping\_rounds     & 10 - 100                                  \\ \midrule
Lasso                          & alpha                       & $10^{-3}$ - $10^{3}$ (log scale)          \\ \midrule
Ridge                          & alpha                       & $10^{-3}$ - $10^{3}$ (log scale)          \\ \midrule
\multirow{2}{*}{\gls{enet}}    & alpha                       & $10^{-3}$ - $10^{3}$ (log scale)          \\ \cmidrule{2-3}
                               & l1\_ratio                   & 0 - 1                                     \\ \midrule
\multirow{5}{*}{\gls{rf}}      & n\_estimators               & 100 - 300                                 \\ \cmidrule{2-3}
                               & max\_depth                  & 2 - 15                                    \\ \cmidrule{2-3}
                               & min\_samples\_split         & 2 - 10                                    \\ \cmidrule{2-3}
                               & min\_samples\_leaf          & 1 - 10                                    \\ \cmidrule{2-3}
                               & max\_features               & \{sqrt, log2\}                            \\ \bottomrule
\end{tabular}
\label{tab:optuna_model_configurations}
\caption{Optuna model configuration ranges.}
\end{table*}
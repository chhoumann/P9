\subsection{Optimization Framework}\label{sec:optimization-framework}
In this section we introduce our optimization framework built on the Optuna framework.
Our goal...
Optuna is a hyperparameter optimization framework designed for direct integration with Python. Its dynamic embedding capability allows hyperparameters to be defined and adjusted within the code during execution, providing additional flexibility and ease of debugging. 
Optuna uses advanced sampling strategies to explore promising areas of the search space and employs pruning techniques to terminate unpromising trials early, optimizing computational resource use. 
It also supports scaling across multiple machines by distributing the optimization process, allowing for concurrent optimization. 
Additionally, tools are provided to identify and focus on the most impactful parameters, aiding in the efficient handling of high-dimensional search spaces. 
Because it is essential for us to identify the optimal configuration of model and preprocessing techniques for that model on a per-oxide basis, these factors make Optuna an ideal choice as the basis of our optimization framework.
Optunas flexibility meant that it was easy to customize the optimization process to solve this problem and integrate it with our existing codebase.  

Optuna for its flexibility and efficiency in exploring the vast search space of configurations.
% Optuna allows for great flexiblity in exploring various search spaces due to its modular design.
% In addition to this modularity, Optuna uses a "define-by-run" optimization strategy.
% Rather than being confined to a fixed order and range of exploration, Optuna can dynamically adjust regions based on the results of previous trials.
% Introduction of the optimization framework
    % What is the goal of the optimization framework?
    % Why Optuna?
        % Explanation of what optuna is and why it is useful for our purposes
        % Should elaborate on this:
            % This framework facilitates automated hyperparameter optimization, allowing us to  efficiently explore a vast search space of model and preprocessing configurations.
% how did we do it?
    % What steps did we take to implement the optimization framework?
    % What are the key components of the optimization framework?
% show diagram or pseudocode
% Explain why we did it this way
    % Why did we choose this approach?
    % What are the benefits of this approach?
    % How does this approach help us achieve our goal?

   
    
% Next, we implemented an experimental framework using the Optuna optimization library~\cite{optuna_2019}.
% This framework facilitates automated hyperparameter optimization, allowing us to efficiently explore a vast search space of model and preprocessing configurations.
% The specifics of this framework are discussed in Section~\ref{sec:optimization_framework}.


% Optuna uses python syntax instead of some propriety syntax
% Optuna brings the optimization into the space of the program rather than outside
    % Meaning you can embed it directly in functions etc.
    % Easier to debug
    % Can use python language such as looping etc.
% Instead of having parameters set you change them so they are sampled using the suggest_* methods
    % This is also helpful because it allows you to optimize any parameter, even for preprocessing etc. in the same objective function
% There are two parts of the hyperparameters optimizer: Sampling strategy and Pruning strategy
    % Sampling strategy determines where to look
        % Uses bayesian filtering to find places where it has had the best results and focus in on those
        % As Optuna tries to minimize/maximize the objective function it focuses in on the best areas and makes more trials there
        % There are multiple samplers - Even the traditional ones
        % Choosing the right sampler is sort of a heuristic 
    % Pruning strategy can terminate trials early that are not promising so that the compute can be dedicated to more promising trials
        % Basically trials that have a slow start and will never be able to make up for that slow start, are pruned
% Optuna is very easy to scale up. It allows you to use a single database across multiple machines
    % This means that Optuna will let you use multiple computers to optimize over the search space at the same time
    % Its called asynchronous parallelization of trials - One trial could start later than the other
    % Near linear scaling with the number of machines
% Has tools to help you determine most important parameters to avoid curse of dimensionality
    % get_param_importances
    % It works by running a small number of trials and then returns this information to you
    % Helps you dial in where optuna should be focusing to get most optimal results

\section{Related Work}\label{sec:related-work}
In addressing the challenge of predicting major oxide compositions from \gls{libs} data, our investigation intersects with a broad spectrum of existing research.
Key strategies include the integration of machine learning and deep learning models, the incorporation of domain knowledge, effective preprocessing techniques, and dimensionality reduction methods.
These approaches collectively aim to manage the complexities inherent in \gls{libs} data and improve predictive performance.
We review existing and relevant work through a thematic taxonomy, highlighting their potential applications in our study.

\subsection{Machine Learning Models in LIBS Analysis}
Several studies have applied machine learning models to analyze \gls{libs} data, aiming to predict major oxide compositions with high accuracy.

\citet{andersonPostlandingMajorElement2022} utilized machine learning models to quantify major oxides on Mars using the SuperCam instrument on the Perseverance rover.
Their approach involved extensive preprocessing and normalization of \gls{libs} spectra, followed by the development of multivariate regression models for each oxide.
They demonstrated that blending different models, such as \gls{gbr} and \gls{pls} for \ce{SiO2}, could improve prediction accuracy.
Their study serves as a benchmark for model performance on \gls{libs} spectra and offers insights into model selection for similar datasets.

\citet{shi_svr_libs_2015} compared the performance of \gls{svr} and \gls{plsr} for quantitative analysis of the major elements \ce{Si}, \ce{Ca}, \ce{Mg}, \ce{Fe}, and \ce{Al} in sedimentary rock samples using \gls{libs} data.
They optimized the \gls{svr} model parameters using a genetic algorithm and cross-validation, selecting 20 characteristic emission lines as input features without dimensionality reduction.
Their results were evaluated using the \gls{rmse} and \gls{rsd} of predicted versus measured concentrations and showed that the non-linear \gls{svr} model significantly outperformed the linear \gls{plsr} model at predicting elemental concentrations.
The superior performance of \gls{svr} was attributed to its ability to handle non-linearities and matrix effects in the complex geological samples, demonstrating the potential of this machine learning technique for quantitative \gls{libs} analysis in geoscience applications.

\citet{el_haddad_ann_2013} explored the application of \gls{ann} for quantitative analysis of soil samples using \gls{libs}, employing a three-layer perceptron \gls{ann} architecture to address matrix effects and nonlinearities.
They demonstrated that \gls{ann} is efficient for predicting the concentrations of \ce{Al}, \ce{Ca}, \ce{Cu}, and \ce{Fe}.
Incorporating additional spectral lines from other chemical elements, thereby increasing the amount of data input to the model, was also shown to significantly improve predictive accuracy.

\citet{yangConvolutionalNeuralNetwork2022} demonstrated the effectiveness of a deep \gls{cnn} for classifying geochemical samples using \gls{libs} spectra collected at varying distances.
Their model outperformed traditional machine learning approaches, emphasizing the potential of \gls{cnn}s for geochemical sample identification in planetary exploration missions like China's Tianwen-1.

\subsection{Hybrid and Domain-Knowledge-Driven Models}
Incorporating domain knowledge into machine learning models can significantly enhance their interpretability and performance.

\citet{song_DF-K-ELM} introduced a hybrid model, \gls{df}-\gls{k-elm}, which integrates domain knowledge-based spectral lines with kernel extreme learning machines.
This method was particularly effective across multiple regression tasks, demonstrating improved accuracy and generalizability.
The integration of domain-specific insights allowed the model to adhere more closely to the physical principles underlying \gls{libs} quantification, making it highly relevant for applications requiring model interpretability.

\citet{sunMachineLearningTransfer2021} applied transfer learning to \gls{libs} spectral data analysis, significantly improving model performance in rock classification on Mars.
By leveraging knowledge from one domain to address related problems in another, their approach addressed the physical matrix effect, enhancing the robustness of the models for rock classification.

\subsection{Preprocessing and Feature Engineering}
Effective preprocessing and feature engineering are critical for enhancing the robustness of \gls{libs} models.

\citet{jeonEffectsFeatureEngineering2024} investigated the effects of various feature-engineering techniques on the robustness of \gls{libs} models for steel classification.
They developed a remote \gls{libs} system to classify six steel types, using various feature-engineering and machine learning algorithms, including \gls{svm} and \gls{fcnn}, to handle different laser energies in test datasets.
They found that using intensity ratios, which involve comparing specific spectral line intensities, significantly improved model robustness under varying measurement conditions.
This approach effectively filtered out noise and enhanced the model's performance, demonstrating the importance of appropriate feature-engineering method.

\citet{Huang2015AnEA} conducted a systematic analysis of data preprocessing techniques, emphasizing the need for tailored strategies to enhance model accuracy.
Evaluating methods such as feature selection, case selection, scaling, and missing data treatments, they demonstrate that the effectiveness of these techniques varies markedly across different datasets and machine learning algorithms.
Their findings underscore the interdependent relationship between preprocessing techniques and model selection, which is crucial for optimizing predictive performance.

\subsection{Dimensionality Reduction Techniques}
Dimensionality reduction techniques such as \gls{pca} play a crucial role in managing the high-dimensional nature of \gls{libs} data.

\cite{pca_review_paper} conducted a comprehensive review of \gls{pca} applied in a \gls{libs} context. 
Their review highlighted several studies that succesfully deployed \gls{pca}.
For example, \cite{moncayo_pca} used \gls{pca} to analyze megapixel elemental maps composed of more than 1 million \gls{libs} spectra. 
\gls{pca} successfully separated the contributions of various minerals, including those present in low amounts, highlighting the power of \gls{pca} in handling highly diverse samples.

Another example is \citet{porizka_pca} used \gls{pca} to filter outliers and classify samples according to their matrix composition, such as \ce{Al}, \ce{Ca}, \ce{Na}, and \ce{Si}. 
This classification was followed by a univariate calibration of copper (\ce{Cu}) in soil samples, which resulted in a reduced bias. 
\gls{pca} was employed to discriminate individual rocks based on their overall elemental composition and they showed that \gls{pca} effectively addressed matrix effects that can significantly impact the accuracy of analytical results.
These studies among others highlighted by \citet{pca_review_paper} demonstrate the effectiveness of \gls{pca} as a preprocessing technique in \gls{libs} analysis.

\citet{sirven_pca_ann_plsr} investigated the influence of matrix effects on the performance of quantitative analysis of chromium (\ce{Cr}) in soil samples using \gls{libs}. 
\gls{pca} was used to classify spectra from two different soils and to detect outliers. 
\gls{pca} was successful in separating spectra from agricultural soil and kaolinite in the plane of the first two components. 
Additionally, \gls{pca} was employed to identify and remove outliers from the data set, enhancing the accuracy of subsequent analyses using \gls{ann}s and \gls{plsr}.
This study demonstrated the utility of \gls{pca} in managing matrix effects and improving the accuracy of quantitative \gls{libs} analysis.
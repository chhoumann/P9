\section{Related Work}\label{sec:related-work}
In addressing the challenge of predicting major oxide compositions from \gls{libs} data, our investigation intersects with a broad spectrum of existing research.
Key strategies include the integration of machine learning and deep learning models, the incorporation of domain knowledge, effective preprocessing techniques, and dimensionality reduction methods.
These approaches collectively aim to manage the complexities inherent in \gls{libs} data and improve predictive performance.
We review existing and relevant work through a thematic taxonomy, highlighting their potential applications in our study.

\subsection{Machine Learning Models in \gls{libs} Analysis}
Several studies have applied machine learning models to analyze \gls{libs} data, aiming to predict major oxide compositions with high accuracy.

\citet{andersonPostlandingMajorElement2022} utilized machine learning models to quantify major oxides on Mars using the SuperCam instrument on the Perseverance rover.
Their approach involved extensive preprocessing and normalization of \gls{libs} spectra, followed by the development of multivariate regression models for each oxide.
They demonstrated that blending different models, such as \gls{gbr} and \gls{pls} for \ce{SiO2}, could improve prediction accuracy.
Their study serves as a benchmark for model performance on \gls{libs} spectra and offers insights into model selection for similar datasets.

\citet{shi_svr_libs_2015} compared the performance of \gls{svr} and \gls{pls} regression for quantitative analysis of the major elements \ce{Si}, \ce{Ca}, \ce{Mg}, \ce{Fe}, and \ce{Al} in sedimentary rock samples using \gls{libs} data.
They optimized the \gls{svr} model parameters using a genetic algorithm and cross-validation, selecting 20 characteristic emission lines as input features without dimensionality reduction.
Their results were evaluated using the \gls{rmse} and \gls{rsd} of predicted versus measured concentrations and showed that the non-linear \gls{svr} model significantly outperformed the linear \gls{pls} regression model at predicting elemental concentrations.
The superior performance of \gls{svr} was attributed to its ability to handle non-linearities and matrix effects in the complex geological samples, demonstrating the potential of this machine learning technique for quantitative \gls{libs} analysis in geoscience applications.

\citet{el_haddad_ann_2013} explored the application of \gls{ann} for quantitative analysis of soil samples using \gls{libs}, employing a three-layer perceptron \gls{ann} architecture to address matrix effects and nonlinearities.
They demonstrated that \gls{ann} is efficient for predicting the concentrations of \ce{Al}, \ce{Ca}, \ce{Cu}, and \ce{Fe}.
Incorporating additional spectral lines from other chemical elements, thereby increasing the amount of data input to the model, was also shown to significantly improve predictive accuracy.

\citet{li2020cnn} developed a method for multi-component quantitative analysis of \gls{libs} data using a deep \gls{cnn}.
Using over 1400 spectra from 23 Chinese standard reference materials, the \gls{cnn} was trained and validated, demonstrating superior performance in regression tasks compared to \gls{bpnn} and \gls{pls} regression models.
The \gls{cnn} achieved lower \gls{rmse} values and higher prediction accuracy, even without removing the continuum background signal from the data, emphasizing the potential of \gls{cnn}s for \gls{libs} data analysis.

\subsection{Hybrid and Domain-Knowledge-Driven Models}
Incorporating domain knowledge into machine learning models can significantly enhance their interpretability and performance.

\citet{song_DF-K-ELM} introduced a hybrid model, \gls{df}-\gls{k-elm}, which integrates domain knowledge-based spectral lines with kernel extreme learning machines.
This method was particularly effective across multiple regression tasks, demonstrating improved accuracy and generalizability.
The integration of domain-specific insights allowed the model to adhere more closely to the physical principles underlying \gls{libs} quantification, making it highly relevant for applications requiring model interpretability.

\citet{sunMachineLearningTransfer2021} applied transfer learning to \gls{libs} spectral data analysis, significantly improving model performance in rock classification on Mars.
By leveraging knowledge from one domain to address related problems in another, their approach addressed the physical matrix effect, enhancing the robustness of the models for rock classification.

\subsection{Preprocessing and Feature Engineering}
Effective preprocessing and feature engineering are critical for enhancing the robustness of \gls{libs} models.

\citet{jeonEffectsFeatureEngineering2024} investigated the effects of various feature-engineering techniques on the robustness of \gls{libs} models for steel classification.
They developed a remote \gls{libs} system to classify six steel types, using various feature-engineering and machine learning algorithms, including \gls{svm} and \gls{fcnn}, to handle different laser energies in test datasets.
They found that using intensity ratios, which involve comparing specific spectral line intensities, significantly improved model robustness under varying measurement conditions.
This approach effectively filtered out noise and enhanced the model's performance, demonstrating the importance of appropriate feature-engineering method.

\citet{Huang2015AnEA} conducted a systematic analysis of data preprocessing techniques, emphasizing the need for tailored strategies to enhance model accuracy.
Evaluating methods such as feature selection, case selection, scaling, and missing data treatments, they demonstrate that the effectiveness of these techniques varies markedly across different datasets and machine learning algorithms.
Their findings underscore the interdependent relationship between preprocessing techniques and model selection, which is crucial for optimizing predictive performance.

\subsection{Dimensionality Reduction Techniques}
Dimensionality reduction techniques such as \gls{pca} play a crucial role in managing the high-dimensional nature of \gls{libs} data.

\citet{pca_review_paper} conducted a comprehensive review of \gls{pca} applied within the context of \gls{libs}.
This review highlighted numerous studies that successfully utilized \gls{pca}.
For instance, \citet{moncayo_pca} used \gls{pca} to analyze megapixel elemental maps composed of over one million \gls{libs} spectra.
The \gls{pca} approach effectively separated the contributions of various minerals, including those present in low concentrations, demonstrating its robustness in handling highly diverse samples.

In another example, \citet{porizka_pca} employed \gls{pca} to filter outliers and classify samples based on their matrix composition, including elements such as \ce{Al}, \ce{Ca}, \ce{Na}, and \ce{Si}.
This classification was followed by a univariate calibration of copper (\ce{Cu}) in soil samples, resulting in reduced bias.
Additionally, \gls{pca} was used to discriminate individual rocks based on their overall elemental composition, effectively addressing matrix effects that can significantly impact the accuracy of analytical results.
These studies, among others highlighted by \cite{pca_review_paper}, underscore the effectiveness of \gls{pca} as a preprocessing technique in \gls{libs} analysis.

\citet{sirven_pca_ann_plsr} investigated the influence of matrix effects on the performance of quantitative analysis of chromium (\ce{Cr}) in soil samples using \gls{libs}.
\gls{pca} was used to classify spectra from two different soils and to detect outliers.
It successfully separated spectra from agricultural soil and kaolinite in the plane of the first two components.
Furthermore, \gls{pca} was used to identify and remove outliers from the dataset, enhancing the accuracy of subsequent analyses using \gls{ann}s and \gls{pls} regression.
This study demonstrated the utility of \gls{pca} in managing matrix effects and improving the accuracy of quantitative \gls{libs} analysis.